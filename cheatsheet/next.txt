https://github.com/andycai/cprimer
https://github.com/Kristories/awesome-guidelines
https://github.com/Panglot/HighQualityCode
https://github.com/kippy620/Note/blob/master/CodeComplete2/11.1_ConsiderationsInChoosingGoodName.md

https://github.com/weien8899/practical-programming-books/blob/b12dbedd1173d0b820d266798b7b5c562489a4c0/README.md

1.http://pac.itzmx.com/abc.pac
2.https://pac.mcplay.cn/jp.pac


http://xahrss.xa.gov.cn/fwdt/
http://xahrss.xa.gov.cn/

https://github.com/whl1729/note
https://www.cnblogs.com/f-ck-need-u/p/7048359.html
https://github.com/freelancer-leon/notes
https://www.cnblogs.com/littleatp/p/5878763.html
http://re2c.org/examples/example_08.html

https://github.com/0079123/myBusiness/blob/b9c339f50952dd9b50360eafd6a351beadb9c176/%E4%BD%BF%E7%94%A8OpenSSL%E7%94%9F%E6%88%90%E5%90%AB%E6%9C%89Subject%20Alternative%20Name(SAN)%E7%9A%84%E8%AF%81%E4%B9%A6.md

github : emailAddress_default commonName_default

https://www.jianshu.com/p/2dd54cd3f553
https://www.jianshu.com/p/5ae60dec2381


胆囊炎、胆石症患者的日常饮食应注意什么
(1)胆囊炎在急性发作期，忌食油炸、煎的食物，忌食蛋类、肉汤及饮酒；进食应限于低脂肪、低蛋白、少量易消化的流食或半流食，随着病症的消退可逐渐加入少量脂肪及蛋白食物，如瘦肉、鱼、蛋、奶和水果及鲜菜等。
(2)慢性胆囊炎患者，平日进食应以清淡、易消化的食物为主，应进大量饮料(1500～2000ml)，以稀释胆汁。
   每2～3小时进食1次，以刺激胆汁分泌。吃易消化的蛋白质，每天50g。勿吃动物脑、肾、蛋黄、油炸食物、辛辣品。
(3)胆囊炎、胆石症患者，在饮食规律方面，宜定时定量，少吃多餐，不宜过饱。在饮食结构上，严格控制脂肪和含胆固醇食物，
   如肥肉、油炸食品、动物内脏等，因为胆结石形成与体内胆固醇过高和代谢障碍有一定关系。不可饮酒和进食辛辣食物，
   宜多吃萝卜、青菜、豆类、豆浆等副食。萝卜有利胆作用，并能帮助脂肪的消化吸收；青菜含大量维生素、纤维素；
   豆类含丰富的植物蛋白。此外，还应补充一些水果、果汁等，以弥补炎症造成的津液和维生素的损失。
(4)胆囊炎、胆石症患者 一般宜进低脂肪、低胆固醇饮食。肥肉，油炸食品，含油脂多的干果、子仁类食物及蛋黄，动物脑、肝、
   肾及鱼子等食品均宜严格控制。平时饮食亦应进易消化、少渣滓食物以避免产生气体。一切酒类、刺激性食物、浓烈的调味品均
   可促进胆囊收缩，使胆道括约肌不能及时松弛，造成胆汁流出，从而使胆囊炎急性发作，所以均应避免。急性发作时宜予低脂、
   易消化半流食或流食；重者应予禁食、胃肠减压及静脉补液。
胆囊炎好发于中年人
胆囊炎是一种比较常见的外科急腹症，发病率仅次于急性阑尾炎。一般多发生在中年人。从医学理论上讲，胆囊炎可以分为急性和慢性，
但是实际上大多数为慢性，开始几次发病症状很轻，疼痛不太厉害，常被误认为胃病而不被引起注意，随后病变逐渐严重，在某些诱因作用下，
突然表现为急性发作，上腹部靠右边剧烈地绞痛，不敢直腰，只好用手保护腹部，不敢碰，甚至疼得在地上打滚和喊叫。



|"<一些符号>"   | 字符的字面含义。逐字匹配引号内的每个字符。
|/              | 向前匹配。如果在匹配的模版中的"/"后跟有后续表达式，只匹配模版中"/"前 面的部分。如：如果输入 A01，那么在模版 A0/1 中的 A0 是匹配的
|<>             | 位于模式开头的尖括号内的一个或者一列名字，使那个模式只应用于指定的起始状态。
| EOF           | 只用于flex中，这个特殊模式匹配文件的结尾。

# 数据是设计的依据，数据结构说明了数据自身的依赖关系和递归关系。设计注重形式(可读性), 是语义性的数据和数据间关系被管理。
# 数据的申请、建立和查询、释放。数据关系的构建、使用和释放。所以，设计是描述数据和数据关系的逻辑。DRY(避免无效重复
# 数据可以有不同的形式化，协议格式，内存格式、存储格式等等
rtud的数据有三种格式: 内存格式，磁盘格式和协议格式。 rtud代码就是为了控制数据如何在多种格式之间转换。
而控制的部分来源配置文件，转换的部分需要考虑HOOK和日志。
程序的状态值反映了协议数据包之间关系 和 数据之间依赖关系。
数据是需求，格式是设计，数据关系到内存格式、磁盘格式和协议格式的依赖是设计的核心。

http://perugini.cps.udayton.edu/teaching/books/SPUC/www/lecture_notes/lex.html
https://github.com/tuvtran/project-based-learning
https://github.com/hongmi/cpp-primer-4-exercises/tree/master/chapter-01
http://blog.chinaunix.net/uid-20106293-id-142129.html
http://blog.chinaunix.net/uid-20106293-id-142128.html
http://blog.chinaunix.net/uid-20106293-id-142127.html
http://blog.chinaunix.net/uid-20106293-id-142126.html

# flex yacc
http://blog.chinaunix.net/uid-20106293-id-142131.html
http://blog.chinaunix.net/uid-20106293-id-142118.html

# Dokan
https://github.com/forger/MountFTP
dropbear + sshftp
notepad++ 中nppftp基本可以满足要求


# RTU 论文
https://www.doc88.com/p-341816150691.html
定期测试、点名测试、告警测试、模拟告警测试。




https://baike.baidu.com/item/%E5%85%89%E7%BA%A4%E5%9C%A8%E7%BA%BF%E8%87%AA%E5%8A%A8%E7%9B%91%E6%B5%8B%E5%91%8A%E8%AD%A6%E7%B3%BB%E7%BB%9F/5139744

awk: 数据的选择和变换操作；信息检索和文本操作。
0. 动作与模式: 1. 模式或动作二者都可以但不能同时省略。
    如果一个模式没有动作，简单的把匹配的行复制到输出。(所以匹配多个模式的行可能被打印多次)。 没有动作的动作是输出匹配行
    如果一个动作没有模式，则这个动作在所有输入上进行。(不匹配模式的行被忽略)。               没有模式的模式是匹配所有行
    因为模式和动作都是可选的，动作必须被包围在花括号中来区别于模式。
    2. 在动作之前的模式充当决定一个动作是否执行的选择者。有多种多样的表达式可以被用做模式: 正则表达式，
算术关系表达式，字符串值的表达式，和它们的任意的布尔组合。BEGIN 在第一个记录被读取之前和 END 最后一个记录已经被处理之后
1. 多输入 1. 一个或多个文件: 命令行支持指定多个文件，
          2. 标准输入: 或通过cat和管道也可以实现多文件输入)
          3. 其它命令的输出: 
2. 多输出 : 1. print printf 和 sprintf 简单输出 指定格式输出和定向格式输出
            2. 生成多个输出文件，'>'新建 '>>'追加 # { print $1 >"foo1"; print $2 >"foo2" } 或 print $1 >>"foo"
            3. 默认情况下，print printf输出到stdout中。
3. 行模式匹配: 
 1. 输入的每行都要依次针对每个模式做匹配。对于每个匹配的模式，执行相关的动作。
    以'行'作为模式匹配的最大单元，以'字段'作为模式的最小单元。
    以'行'作为动作执行(数据操作)最大单位；以'字段'作为动作执行最小单元。
    一行数据可以被检索多次，每次检索或多次检索成功后，会执行输出或者数组统计操作。
 2. 如果记录分隔符为空，把空输入行作为记录分隔符，并把空格、tab 和换行作为字段分隔符处理。
    行: NR,RS(记录分隔符),ORS
    字段:NF,FS(字段分隔符),OFS 
    FS: 可以同时使用多个域分隔符，这时应该把分隔符写成放到方括号中，如$awk -F'[:\t]' '{print $1,$3}' test，表示以空格、冒号和tab作为分隔符。
    OFS: 输出域的分隔符默认是一个空格，保存在OFS中。如$ awk -F: '{print $1,$5}' test，$1和$5间的逗号就是OFS的值。
4. 模式匹配: 字符串处理，数值计算，变量判断和数组元素的字符串或数值判断，以及正则表达式的匹配结果之间的布尔异或操作。
 1. /正则表达式/：正则表达式是包围在斜杠内的文字的字符串。圆括号用做组合，| 用做选择，+ 用做'一或多个'，? 用于'零或一个'。
 2. 关系表达式：常用的关系算符 <、<=、==、!=、>=、> 的关系表达式，可以是字符串或数字的比较，如$2>$1选择第二个字段比第一个字段长的行。
    在关系测试中，如果操作数(operand)都不是数值，则做字符串比较；否则做数值比较。
 3. 模式匹配表达式：~ 和 !~ 指定任何行或字段或变量匹配(或不匹配)一个正则表达式。
    脱字符号 ^ 指称一行或一个字段的开始处；美元号 $ 指称结束处。
    $1 ~ /[jJ]ohn/ 第一个字段匹配“john”或“John”的所有行。 $1 ~ /^[jJ]ohn$/ 精确的限制它为 [jJ]ohn。
 4. 模式的组合: 可以是模式的使用算符 ||(或)、&&(与)和 !(非)的任意布尔组合。
 5. 模式，模式：指定一个行的范围。/start/, /stop/ 或者 NR == 100, NR == 200 { ... }
    范围模板匹配从第一个模板的第一次出现到第二个模板的第一次出现之间所有行。如果有一个模板没出现，则匹配到开头或末尾。
 7. BEGIN：让用户指定在第一条输入记录被处理之前所发生的动作，通常可在这里设置全局变量。
    END：让用户在最后一条输入记录被读取之后发生的动作。
    BEGIN 和 END 从而提供了在处理之前和之后获得控制的方式，用来做初始化和总结。
    如果 BEGIN 出现，它必须是第一模式；END 必须是最后一个模式，如果用到了的话。
5. 动作执行: 数值计算结果，字符串截断替换和数组(k-v数组)运算，以及for,while,if-else控制语句
 1. awk 动作是用换行或分号终止的动作语句的序列。这些动作语句可以被用来做各种各样的簿记和字符串操纵任务。 
 2. 变量、表达式和赋值 : a.在awk中，变量不需要定义就可以直接使用，变量类型可以是数字或字符串。注意，字符串一定要用双引号。
    b. 可以在命令行中给变量赋值，然后将这个变量传输给awk脚本。如$ awk -F: -f awkscript month=4 year=2004 test，
    x = 1; x = "smith"; x = "3" + "4" 算术算符有 +、-、*、/、%(模)。
    C 语言的增加 ++ 和减少 ?? 算符也可用，还有赋值算符 +=、-=、*=、/=、%=。
 3. 字段变量:可以被赋值; 一个字段被认为是数值还是字符串依赖于上下文; 
 4. 输出命令 printf print
 5. 数组    : 数组元素不用声明；在被提及到的时候才导致它的存在。下标可以有任何非空的值，包括非数值的字符串.
              delete函数用于删除数组元素。如：$ awk '{line[x++]=$1} END{for(x in line) delete(line[x])}' test。
 6. 内置函数: length sqrt log exp int substr index sprintf split(s, array, sep)
 7. 控制流命令: break 语句导致从围绕它 while 或 for 中立即退出，
                continue 语句导致开始下一次重复。
                next next语句从输入文件中读取一行，然后从头开始执行awk脚本
                exit 语句用于结束awk程序，但不会略过END块。退出状态为0代表成功，非零值表示出错。
 注释: 在 awk 程序中可以放置注释: 它们开始于字符 # 并结束于本行的结束处。
6. 环境变量: 环境变量，BEGIN(特殊模式)，END(特殊模式)，数组(统计)，内置函数
7. 赋值:  字段可以被赋值。行也可以被赋值
8. 模式匹配型条件和执行语句中条件:  awk '{if ($0 ~ /pattern/) print $0}' 执行语句内条件判断
                                    awk '$0 ~ /pattern/ {print $0}'      模式匹配型条件判断
awk -F: 'NF != 7{printf("line %d:%s\n",NR,$0)} 
         $1 !~ /[A-Za-z0-9]/{printf("line %d,%s\n,NR,$0)} 
         $2 == "*" {printf("line %d, no password: %s\n",NR,$0)}'         模式匹配型多条件判断
awk -F: '{ if(NF != 7) {printf("line %d:%s\n",NR,$0)}; 
           if($1 !~ /[A-Za-z0-9]/){ printf("line %d,%s\n,NR,$0)};
           if($2 == "*"){printf("line %d, no password: %s\n",NR,$0)}} '  执行语句内多条件判断

length 等价于 length($0) 行记录中字符个数； length($1) 第一个字段字符个数 
NF 是一行中字段个数，不是字符个数。FS 是字段分隔符，分隔符可以为一个集合 [:\t;] 

awk 'NR==FNR { # some actions; next} # other condition {# other actions}' file1 file2
awk 'NR==FNR{a[$0];next} $0 in a' file1 file2 # 打印既在file1又在file2的行

           
awk 支持正则表达式，所以可以取代grep # awk '{if ($0 ~ /pattern/) print $0}' # 只有动作没有模式。没模式时，动作应用于所有行
                                    # awk '$0 ~ /pattern/ {print $0}'      # 有模式有动作。$0 表示当前行数据
                                    # awk '/pattern/ {print $0}'           # 有模式有动作。不指定记录时，模式匹配当前行
                                    # awk '/pattern/ {print}'              # 有模式有动作。函数不指定记录时，默认参数为当前行
                                    # awk '/pattern/'                      # 有模式无动作。没动作时，动作就是输出当前行。
awk 内嵌sub,gsub函数，所以可以取代sed # awk '{sub(/pattern/,"foobar")}1' - sed 's/pattern/foobar/'   # sub对应s/pattern/replace/
                                    # awk '{gsub(/pattern/,"foobar")}1' - sed 's/pattern/foobar/g' # gsub对应s/pattern/replace/g

print 不支持格式化，当时print也支持 "\n\t\r" 等转义字符。 OFMT 可以对数值输出格式进行一些定义

print [ ExpressionList ] [ Redirection ] [ Expression ]
    print 语句将 ExpressionList 参数指定的每个表达式的值写至标准输出。每个表达式由 OFS 特殊变量的当前值隔开，
且每个记录由 ORS 特殊变量的当前值终止。
    可以使用 Redirection 参数重定向输出，此参数可指定用 >、>>和 | 进行的三种输出重定向。Redirection 参数指定如何重定向输出，
而 Expression 参数是文件的路径名称。(当 Redirection 参数是 > 或 >> 时)或命令的名称(当 Redirection 参数是 | 时)。
在 print 语句中用逗号分隔的项，在输出的时候会用当前输出字段分隔符分隔开。没有用逗号分隔的项会串联起来，# 逗号起视作字段分隔符

printf Format [ , ExpressionList ] [ Redirection ] [ Expression ]
printf : # 除了 c 转换规范（%c）不同外，printf 语句和 printf 命令起完全相同的作用。
对于 c 转换规范：如果自变量具有一个数字值，则编码是该值的字符将输出。
                 如果值是零或不是字符集中的任何字符的编码，则行为未定义。
                 如果自变量不具有数字值，则输出字符串值的第一个字符；
                 如果字符串不包含任何字符，则行为未定义。

awk 变量依据上下文而被接纳为数值(浮点数)或字符串值。
    x = 1 # x 明显的是个数
    x = "smith" # 明显的是个字符串
    在上下文需要的时候，把字符串转换为数或反之。例如
    x = "3" + "4" # 把 7 赋值给 x。
    缺省的，(不是内置的)变量被初始化为空字符串，它有为零的数值；这消除了大多数对 BEGIN 段落的需要。
    awk '$3 == "Ann" { $3 = "Christian"; print}' testfile
    awk '/Ann/{$8 += 12; print $8}' testfile #找到包含Ann的记录，并将该条记录的第八个域的值+=12，最后再打印输出。
                 
运算符 # 描述
空格 # 连接              相当于lua中 '..' 连接字符串
in   # 数组成员          包含在数组成员中
==   # 变量匹配          值或字符串相等
!=   # 不等于            值或字符串不相等
~    # 匹配正则表达式    awk '$1~/Mary/' employees,  # 表示第一个域($1)中包含Mary的被打印
!~   # 不匹配正则表达式  awk '$1!~/Mary/' employees, # 表示第一个域($1)中不包含Mary的被打印
=,+=,-=,*=,/=,%=:      # 赋值运算符.
-,+,*,/,%,^(x^y[乘方]) # 数学运算符.
+ - !                  # 一元加，减和逻辑非
^ ***                  # 求幂
++ --                  # 增加或减少，作为前缀或后缀
&&, ||, !:             # 逻辑运算符.
,:                     # 表示范围, awk '/Tom/,/Mary/' datafile 其规则可参照sed中逗号运算符.
<,>,<=,>=,!=,==      # 关系运算符 awk '$3>5000 {print $3}' datafile
cond ? expr1 : expr2 # 条件表达式 awk '{max = $1 > $2 ? $1 : $2; print max}' datafile

conditional expression1 expression2: expression3，
例如：$ awk '{max = {$1 > $3} $1: $3: print max}' test。如果第一个域大于第三个域，$1就赋值给max，否则$3就赋值给max。
$ awk '$1 + $2 < 100' test。如果第一和第二个域相加大于100，则打印这些行。
$ awk '$1 > 5 && $2 < 10' test,如果第一个域大于5，并且第二个域小于10，则打印这些行。

if...in 需要以下语法： if ( Variable in Array ) { Statement }
if...in 语句搜索是否存在的 Array 元素。如果找到 Array 元素，就执行该语句。


1. Expression | getline [ Variable ] 
    从来自 Expression 参数指定的命令的输出中通过管道传送的流中读取一个输入记录，并将该记录的值指定给 Variable 参数指定的变量。
如果当前未打开将 Expression 参数的值作为其命令名称的流，则创建流。创建的流等同于调用 popen 子例程，此时 Command 参数取 Expression 
参数的值且 Mode 参数设置为一个是 r 的值。只要流保留打开且 Expression 参数求得同一个字符串，则对 getline 函数的每次后续调用读取
另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置为从流读取的记录。
2. getline [ Variable ] < Expression 
    从 Expression 参数指定的文件读取输入的下一个记录，并将 Variable 参数指定的变量设置为该记录的值。只要流保留打开且 Expression 
参数对同一个字符串求值，则对 getline 函数的每次后续调用读取另一个记录。如果未指定 Variable 参数，则 $0 记录变量和 NF 特殊变量设置
为从流读取的记录。
3. getline [ Variable ] 
    将 Variable 参数指定的变量设置为从当前输入文件读取的下一个输入记录。如果未指定 Variable 参数，则 $0 记录变量设置为该记录的值，
还将设置 NF、NR 和 FNR 特殊变量。

awk 'BEGIN{ "date" | getline d; print d}' test。 
awk 'BEGIN{while( "ls" | getline) print}'
awk ' BEGIN { printf "What is your name "; getline name < "/dev/tty" } $1 ~name {print "Found" name on line } END{print "See you," name  } ' cbtc.sh
awk 'BEGIN{while (getline < "/etc/passwd" > 0) lc++; print lc}'


1. 面向整行的函数 # i\ a\ c\ n d
1.1 i\   # 行前插入  i用于在指定行前面插入其他文本,使用方法: sed [options] '[range]i [string]' [filename]
    i\ 函数表现得等同于 a\ 函数，除了<文本>在匹配行之前写入输出之外。关于 a\ 函数的所有其他注释同样适用于 i\ 函数。
1.2 a\   # 行后插入  a用于在指定行后面追加其他文本,使用方法: sed [options] '[range]a [string]' [filename]
    a\ 函数导致在匹配它的地址的行之后把参数<文本>写入输出。a\ 命令是天生多行的；a\ 必须出现在一行的结束处，而<文本>可以包含任意数目的行。
    为了保持一行一个命令的构想，内部的换行必须用给换行立即前导上反斜杠字符('\')的方式来隐藏。<文本>参数终止于第一个未隐藏的换行.
    一旦 a\ 函数成功的执行了，<文本>将被写入输出，而不管后来的命令对触发它的行会做些什么。触发的行可以被完全删除掉；
    而<文本>仍会被写入输出。<文本>不被地址匹配所扫描，不尝试对它做编辑命令。它不引起行号计数器的任何变化。
1.3 c\   # 修改      c用于对指定行进行修改,使用方法: sed [options] '[range]c [string]' [filename]
    c\ 函数删除它的地址所选择的那些行，并把它们替代为在<文本>中的行。
    象 a\ 和 i\ 一样，c 必须跟随着被反斜杠隐藏了的换行；并且在<文本>中的内部的换行必须用反斜杠隐藏。
    c\ 命令可以有两个地址，所以可选择一定范围内的行。如果找到，在这个范围内的所有行都被删除，只把<文本>的一个复本写入输出，而不是对每个删除的行都写一个复本。
    在一行已经被 c\ 函数删除之后，在这个已删除的行上将不再尝试进一步的命令。
    如果 a\ 或 r\ 函数在某一行之后添加了文本，而这一行随后被 c 函数变更了，则 c 函数所插入的文本将会放置在 a 或 r 函数的文本之前。
1.4 n   # 下一行
    n 函数从输入读取下一行，替代当前行。当前行被写入输出，如果应该的话。继续执行编辑命令列表在 n 命令之后的部分。
1.5 d   # 删除行  d 函数从文件中删除(不写入输出)匹配它的地址的所有行。
    d还有一个副作用，在这个已删除的行上将不再尝试进一步的命令；在执行了 d 之后，马上就从输入读取一个新行，在新行上从头重新启动编辑命令列表。

2.  替换函数 s
    s    # s<模式><替代><标志> 
<替代>不是模式，在模式中有特殊意义的字符在<替代>中没有特殊意义。反而有特殊意义的字符是:
        & 被替代为匹配<模式>的字符串。
        \d (这里的 d 是一个单一的数字)被替代为同<模式>中第 d 个包围在'\('和'\)'内的部分相匹配的子串。
如果在<模式>中出现嵌套的子串，第 d 个通过计数开分界符 ('\(')来界定。同在模式中一样，特殊字符可以通过前导反斜杠('\')来变为文字。
   # 标志g: 替换默认只对每行的第一处匹配进行,而加上g之后,将对每行所有匹配的字符串进行替换
   # 标志[n]: 数字标志,匹配到的第n次才进行替换
   # 标志p: 类似p命令,这里用作替换命令s的标志,作用都是对处理后的行进行打印,常和-n选项一起用
   # 标志w: 类似w命令,只不过做为了命令s的标志,作用和用法都相同
   # 标志i: 忽略大小写标志,加上i标志之后"origin_string"匹配时不去分大小写字母
   # 标志e: 把替换后的行作为shell命令执行
   # 替换命令的标志使可以组合使用的,例如:sed -n 's/hello/hi/gpw output.txt' test.txt
   # 分割标志/可以用任意字符替换,sed根据s后边紧跟的第一个字符判断你用了什么做分隔符
   # 匹配或者替换字符串出现分割标志的时候要用''进行转义zhuanyi
g  # 配合s全部替换
在<模式>和上下文地址之间的唯一区别是上下文地址必须用斜杠字符('/')来界定；<模式>可以用不是空格或换行的任何其他字符来界定。
<替代>参数紧接着<模式>的第二个分界字符之后开始，并且它必须立即跟随着分界字符的另一个实例。

3. 输入输出函数
3.1 p
    p 打印函数把寻址到的行写到标准输出文件。在遇到 p 函数的时候就写入它们，而不管后续的编辑命令对这些行会做些什么。
3.2 w <文件名>
    w 写函数把寻址到的行写到<文件名>指名的文件中。如果这个文件以前就存在，则覆盖它；否则，就建立它。
    每行都按遇到写函数时现存的样子写入，而不管后续的编辑命令对这些行会做些什么。
    必须用精确的一个空格分隔 w 和<文件名>。在 s 函数的 w 标志之后和写函数中可以提及的不同的文件名字合起来的最大数目为 10 个。
3.3 r <文件名> # 读
    读函数读入<文件名>的内容，并把它们添加到匹配这个地址的行的后面。
    如果 r 和 a 函数在同一行上执行，来自 a 函数和 r 函数的文本按照这些函数执行的次序写入输出。
    必须用精确的一个空格分隔 r 和<文件名>。
    如果 r 函数提及的文件不能打开，它被当作一个空文件，而不是一个错误，所以不给出诊断信息。

4.  多输入行函数
有三个用大写字母拼写的函数特殊处理包含内嵌换行的模式空间；它们主要意图提供跨越输入中的行的模式匹配。
4.1 N:读入下一行，追加到模式空间行后面，此时模式空间中有两行。正则表达式符号^和$含义分别为^匹配模式空间的最开始，而$是匹配模式空间的最后位置。
    在模式空间中把下一行添加到当前行之后；两个输入行用一个内嵌的换行分隔。模式匹配可以延伸跨越这个内嵌换行。
4.2 D:删除模式空间的第一行，不读下一行到模式空间。注意，当模式空间仍有内容时，不读入新的输入行，类似形成一个循环。
删除当前模式空间中直到并包括第一个换行字符的所有字符。如果这个模式空间变成了空的(唯一的换行是终止换行)，则从输入读取另一行。
在任何情况下，都再次从编辑命令列表的起始处开始执行。
4.3 P 打印模式空间中的直到并包括第一个换行的所有字符。
注: P 和 D 函数等价于它们对应的小写函数，如果在模式空间中没有内嵌换行的话。

D. 删除模板块的第一行。
N. 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。
P. 打印模板块的第一行。

5. 保存和取回函数
5.1 g:将保持空间的内容拷贝到模式空间中，会将模式空间原来的值覆盖掉。
把保存区域的内容复制到模式空间(销毁模式空间以前的内容)。
5.2 G:将保持空间的内容追加到模式空间中。
G 函数把保存区域的内容添加到模式空间的内容之后；以前和新的内容用换行分隔。
sed G
sed 'G;G'
5.3 h:将模式空间的值拷贝到保持空间，会将保持空间原来的值覆盖掉。
把模式空间的内容复制到保存区域(销毁保存区域以前的内容)。
5.4  H:将模式空间的值追加到保持空间中。
把模式空间的内容添加到保存区域的内容之后；以前和新的内容用换行分隔。
5.5。x:交换模式空间和保持空间的内容。
对换命令交换模式空间和保存区域的内容。

6. 控制流函数
6.1 ! :对其前面的要匹配的范围取反
非命令导致(写在同一行上的)下一个命令，应用到所有的且只能是未被地址部分选择到那些输入行上。
6.2 { -- Grouping
组合命令‘{’导致下一组命令作为一个块而被应用(或不应用)到组合命令的地址所选择的输入行上。在组合控制下的的命令中的
第一个命令可以出现在与‘{’相同的一行或下一行上。组合的命令由自己独立在一行之上的相匹配的‘}’终止。
6.3 :label和b label  : 标注一个标签并跳转。
标号函数在编辑命令列表中标记一个位置，它将来可以被 b 和 t 函数所引用。<标号>可以是八个或更少的字符的任何序列；
如果两个不同的冒号函数有相同的标号，就会生成编译时间诊断信息，而不做执行尝试。
6.4 b<标号> -- branch to label
分支函数导致应用于当前输入行上的编辑命令序列，被立即重新启动到有相同的<标号>的冒号函数的所在位置之后。
如果在所有编辑命令都已经被编译了之后仍没有找到有相同的标号的冒号函数，就会生成一个编译时间诊断信息，而不做执行尝试。
不带有<标号>的 b 函数被当作到编辑命令列表结束处的分支；对当前输入行做应做的无论怎样的处理，并读入其他输入行；编辑命令的列表在这个新行上从头重新启动。
6.5  )t<标号> -- test substitutions
    t 函数测试在当前输入行上是否已经做了任何成功的替换；如果有，它分支到<标号>；否则，它什么都不做。指示已经执行了成功的替换的标志通过如下方式复零:
        1) 读取一个新输入行，或
        2) 执行 a 和 t 函数。
        
7. 杂类函数
7.1 = -- equals
    = 函数向标准输出写入匹配它的地址的行的行号。
7.2 q -- quit
    q 函数导致把当前行写到标准输出(如果应该的话)，任何添加的或读入的文本也被写出，而且执行会被终止。
    
模式 # ^ $ . * [] [^] \(..\) & \< \> x\{m\} x\{m,\} x\{m,n\}
    
1. 不需要地址
: label   Label for b and t commands.
#comment  The comment extends until the next newline
}         The closing bracket of a { } block.
2. 不需要或需要一个地址
=      Print the current line number.
a \
text   Append text, which has each embedded newline preceded by a backslash.
i \
text   Insert text, which has each embedded newline preceded by a backslash.
q [exit-code]
r filename  Append text read from filename.
3. 可以接收地址范围
{       Begin a block of commands (end with a }).
b label Branch to label; if label is omitted, branch to end of script.
t label
  If a s/// has done a successful substitution since the last input line was read and since the last t  or
  T command, then branch to label; if label is omitted, branch to end of script.
c \
text   Replace the selected lines with text, which has each embedded newline preceded by a backslash
d      Delete pattern space.  Start next cycle.
D      Delete  up  to the first embedded newline in the pattern space.  Start next cycle, but skip reading from
       the input if there is still data in the pattern space.
h H    Copy/append pattern space to hold space.
g G    Copy/append hold space to pattern space.
x      Exchange the contents of the hold and pattern spaces.
l      List out the current line in a ‘‘visually unambiguous form.
n N    Read/append the next line of input into the pattern space.
p      Print the current pattern space.
P      Print up to the first embedded newline of the current pattern space.
s/regexp/replacement/
w filename  Write the current pattern space to filename.
y/source/dest/ Transliterate the characters in the pattern space which appear in source to the corresponding  character in dest.


print 和 printf 之间差异，
1. OFS和ORS在print中有效，在printf中无效。即 print $0会自动追加换行; print $1,$2在 $1,$2之间会嵌入空格
2. , 在print中具有ORS分隔功能，无 , 表示字符串之间连接。 , 在printf按照原样输出。
3. printf("%s\n\n", $0) 格式类似函数， print $0 格式类似命令

awk和sed都是"模式-动作"方式的文本处理工具。每行数据可以对应多条"模式-动作"，即: 一行数据可以被处理多次。
sed 通过模式匹配进行定位(还有数值)，使用特定的函数和模式替换对输入进行处理；
awk 通过模式匹配和条件判断语句匹配进行定位(还有数值)，通过特定函数和位置变量赋值对输入数据进行处理。
sed 通过保存空间保存临时数据，保存空间相当于一个变量
awk 通过位置变量、自定义变量、环境变量和关联数组保存临时数据，所以awk处理数据更加强大。

从功能分解上而言: awk处理数据的粒度要比sed更准确，也有更多的控制逻辑，更多的变量类型(数组，内置变量，自定义变量)，更多的内置函数。
所以，如果将要实现的功能落实到代码处理逻辑上，简单行级别处理: 删除，插入，定位后输出行，修改和字段级别的替换使用sed，
当涉及到到统计、字段级别替换、格式化、排序和多文件合并，最好使用awk实现。且awk实现时，能用 执行部分if控制，就别使用 模式控制。

awk 的函数具有lua脚本语言的特性， gsub(r, s [, t]) 
                                  match(s, r [, a]) 
                                  split(s, a [, r]) 
                                  sub(r, s [, t])
                                  substr(s, i [, n]) 
提供了一些默认值，参数可以动态传入。
还有一些命令特性: getline; getline <file; getline var; getline var<file; command | getline [var]; next; print 等空格分割命令行方式；
还提供了数学特性: cos sin int log rand srand 等等
还有时间相关函数: mktime(datespec)  strftime([format [, timestamp[, utc-flag]]]) systime() 
除了扩展性，几乎有了Lua语言所有特性。

sed 缺省的把标准输入复制到标准输出，在把每行写到输出之前可能在其上进行一个或多个编辑命令。每个命令的输入都是所有前面命令的输出。
这种行为可以通过命令行选项来更改。 -n 告诉 sed 不复制所有的行，只复制 p 函数或在 s 函数后 p 标志所指定的行。
    编译命令应用的缺省的线性次序可以通过控制流命令 t 和 b 来变更，即使在应用次序被这些命令改变的时候，
给任何命令的输入仍是任何此前应用的命令的输出。
    [地址1,地址2][函数][参数] # [address-range] function[modifiers]
    1. 一个或两个地址是可以省略的；
    2. 可以用任何数目的空白或 tab 把地址和函数分隔开。
    3. 函数必须出现；
    4. 依据给出的是哪个函数，参数可能是必需的或是可选的；
    5. 忽略在这些行开始处的 tab 字符和空格。
    6. 通过用花括号('{ }')组合(group)命令，可以用一个地址(或地址对)来控制一组命令的应用
    
    地址
    1. 行号地址: 计数器在多个输入文件上累计运行，在打开一个新文件的时候它不被复零。字符 $ 匹配输入文件的最后一行。
    2. 上下文地址是包围在斜杠中('/')的模式('正则表达式') 将 pattern(sed)
      2.1) 字符'\n'匹配内嵌的换行字符，而不是在模式空间结束处的换行。
      2.2) 点'.'匹配除了模式空间的终止换行之外的任何字符。
      2.3) 在顺序的'\('和'\)'之间的正则表达式，在效果上等同于没有它修饰的正则表达式，但它有个副作用，
      2.4) 表达式'\d'意味着与在同一个表达式中先前的'\('和'\)'中包围的表达式所匹配的那些字符同样的字符串。
    3. 地址的数目: 命令可能有 0, 1 或 2 个地址
      3.1) 如果命令没有地址，它应用于输入中每个行。
      3.2) 如果命令有一个地址，它应用于匹配这个地址的所有行。
      3.3) 如果命令有两个地址，它应用于匹配第一个地址的第一行，和直到(并包括)匹配第二个地址的第一个后续行的所有后续行。
           接着在后续的行上再次尝试匹配第一个地址，并重复这个处理。
     sed '144s/hello/world/' input.txt > output.txt      # 特定地址
     sed 's/hello/world/' input.txt > output.txt         # 不指定地址
     sed '/apple/s/hello/world/' input.txt > output.txt  # 模式地址
     sed '4,17s/hello/world/' input.txt > output.txt     # 范围地址
     sed '/apple/!s/hello/world/' input.txt > output.txt # 模式地址:取反
     sed '4,17!s/hello/world/' input.txt > output.txt    # 范围地址:取反
    
输入和输出: 1. 管道，2. 文件(可以一次处理多个文件，行号地址为文件间的累计地址值)
等价:
    sed 's/hello/world/' input.txt > output.txt
    sed 's/hello/world/' < input.txt > output.txt
    cat input.txt | sed 's/hello/world/' - > output.txt
修改 file.txt 而没有任何输出
    sed -i 's/hello/world/p' file.txt  # 不输出任何内容
    sed -n 's/hello/world/p' file.txt  # 只输出匹配替换成功内容
    
awk 使用分号(或换行)来分隔 多个'模式-动作'块；也使用分号和换行来分隔 多动作中的条执行语句。
sed 使用分号(或换行)来分隔 多个'模式-动作'块；也使用分号和换行来分隔多个'模式'。 #  awk '1;{print ""}'  动作1相当于 print $0
awk 模式中，非空字符串和非零数值 被视作匹配所有行的 模式 。         # awk '1{print $0}'  test1.sh 

输入和输出: 1. 管道，2. 文件(可以一次处理多个文件，行号地址为文件间的累计地址值)
等价:
    sed 's/hello/world/' input.txt > output.txt
    sed 's/hello/world/' < input.txt > output.txt
    cat input.txt | sed 's/hello/world/' - > output.txt
修改 file.txt 而没有任何输出
    sed -i 's/hello/world/p' file.txt  # 不输出任何内容
    sed -n 's/hello/world/p' file.txt  # 只输出匹配替换成功内容
模式匹配规则: 等价
    sed 's/hello/world/' input.txt > output.txt
    sed -e 's/hello/world/' input.txt > output.txt
    sed --expression='s/hello/world/' input.txt > output.txt

    echo 's/hello/world/' > myscript.sed
    sed -f myscript.sed input.txt > output.txt
    sed --file=myscript.sed input.txt > output.txt
返回值: q42 返回值等于42
    0: 执行成功
    1: 无效命令、无效模式、无效语法
    2: 一个或多个指定文件不存在
    4: IO错误或者严重的执行错误
    
多编辑命令
    sed '/^foo/d ; s/hello/world/' input.txt > output.txt

    sed -e '/^foo/d' -e 's/hello/world/' input.txt > output.txt

    echo '/^foo/d' > script.sed
    echo 's/hello/world/' >> script.sed
    sed -f script.sed input.txt > output.txt

    echo 's/hello/world/' > script2.sed
    sed -e '/^foo/d' -f script2.sed input.txt > output.txt

bash专注于任务调度；awk专注于行列数据处理。
    read是bash中特殊的行处理内置命令. bash的read是以行为处理单元的，awk被设计成以行为处理单元。read和awk都通过IFS分割字段。
    bash都有字符串、数值和关联数组。  
      bash数值计算 $[] 或者 $(()). awk 直接 +-*/%^. 
      bash字符串处理依赖 ${##} ${%%} ${//} ${::}的方法，awk依赖函数，且函数支持模式替换和数组split
      bash 通过${!array[*]}得到关联数组索引， awk通过for index in array得到索引。通过 if in判断存在。
      bash使用unset删除数组元素和数组；awk使用delete删除。bash能对数组初始化，awk没有对数组初始化的方法。
    bash的判断区分字符串和数字；
      bash字符串用 = != -n -z 数字用-lt -le -gt -ge -eq -ne. 
      awk不区分: == != > >= < <= 都用于字符串和数字，字符串仍支持 ~ !~模式匹配.
      bash 有很多文件相关特性，文件类型(普通、目录、块设备、字符设备、套接字、命名管道和连接文件)，存在与否
                 文件相关特性，可读、可写、可执行；UID、GID、是否为空和sbit特性
                 文件相关特性，新、旧、相等
    bash和awk的关系判断不同
      bash 在 [] 中是 -a -o 和 ! 进行; 在[[]] 中使用 && || 和 !进行; [[]] 支持正则表达式和通配符，[]不支持
        1.无论是[]还是[[]]，都建议对其内变量、字符串使用双引号包围。换句话说，能做字符串比较的时候，不要用数值比较。
        2.当变量可能为空的时候，强烈建议在变量的基础上加上其他辅助字符串。看过/etc/init.d下的脚本的人肯定都见过这种用法。
      awk  使用 && || 和 ! 进行;
    bash和awk 都用printf函数，bash特殊在%b和%p， awk特殊在 %c.
    bash可以调用awk命令，给awk命令传递参数；awk可以调用bash命令，为bash提供数据输出。
    bash有很多扩展方式: 
    
    awk充分发挥C语言特性，数值不等于0和字符串不为空即认为条件为真；数值等于0和字符串为空即认为条件为假
    
    BASH_REMATCH 在 [[ =~ ]] 之后使用，用于捕获模式匹配字符串    # man 3 regex
    一个数组变量，其中的元素由条件结构命令[[的双目运算符"=~"来赋值。
      BASH_REMATCH中下标为夰的元素是字符串中与整个正则表达式匹配的部分。
      BASH_REMATCH中下标为奮的元素是字符串中与第n个括号里面的子模式匹配的部分。
    if [[ "$line" =~ $pattern ]]; then
    
    bash中有四个重要且不易区分的概念；
      文件名(特殊字符串)，字符串，管道(流对象,表示已打开文件, 需要指定描述符名称)，重定向(包括打开文件的过程,需要指定文件名)。
    1. 文件名       sed awk cut tr wc等命令参数
    2. 字符串       $(command)
    3. 管道(流对象) <<<"$string"  <(命令列表) | # <<EOL hear-doc生成一个描述符
    4. 重定向       > >> &> (流与流、流与文件、流与命令 之间关系)
    
    命令支持类型: 文件名; | 管道; < 输入描述符
    
    
    
awk(程序设计
操作对象  是预定义变量和自定义变量
变量类型  字符串 数组和数值
操作手段  除了类似sed中的内置函数外，采用了C语言编程模式，支持关系和算术运算，还有字段操作，对字符串处理功能丰富
操作效果  变量被改变 或 求出统计结果
工作模式 
控制流程  处理一行 if while for break continue 
          AWK行循环 next exit getline

预定义变量的值，是可以改变的；包括 $0 $1 和 FS OFS FNR 和 NR
自定义变量接受三种类型的值，且可以随时改变类型；在算术运算中，非数值的字符串被认为是0值。
> >= < <= == != 可应用于字符串和数值
+ - * / % ^ 只能用于数值; 数值计算更多依赖操作数；字符串处理更多依赖函数；复杂的数值计算也提供了些函数。
~ !~ 表示模式相等，只能用于字符串；
in 可用于if判断和for循环的控制语句中。
模式: 组合模式(&& || !)和范围模式(,)
1. 字符串 : 模式匹配，组合模式，范围模式，字符串处理函数；> == < != 判断, 赋值
2. 数值   : + - * / % ^ 数值处理函数；> >= == < <= != ; 预定义变量的值，赋值
3. 数值   : 赋值，遍历和包含 删除
4. 流处理 : print printf sprintf getline > >> 重定向
5. index是普通匹配，match是模式匹配，另外有RSTART和RLENGTH预定义内置变量和返回匹配数字a可选参数
   substr是基于位置的字符串截取，而sub和gsub是模式替换
   
   
sed程序设计)
11. 全局变量: '模式空间' 和 '保存空间'
1. n N读入下一行，且n会输出， N不会
打印奇数行 sed '{n;d}' file.txt
2. h H g G x 交换两个变量
行连接 sed '1{h}; 1{s/:.*//}; 1{x}; {G}; {s/\n/:/}' file.txt 
3 D P 删除和打印
打印奇数行 sed 'N;P;d' file.txt

22. 分支和循环: 靠跳转实现，类似jmp法
:tag 标签
b 条件跳转
死循环 sed -e ':tag;b tag' file.txt
d 删除本行进入下一轮
t s命令成功则跳转

33. sed程序设计
操作对象  是两个变量  模式空间和保存空间
变量类型  字符串 从一种模式的字符串到另一种模式
操作手段  采用固定的内置函数d,a,i,c,s和n,N,d,D,h,H,g,G,x
操作效果  变量('字符串')被改变，无关系、算术运算
工作模式  sed自动的循环读入每一行，对每一行的处理是由sed顺序执行编辑命令，在执行编辑命令时，
          允许跳转，以形成分支和循环，也许打破sed循环，提前读入下n行。


eval 使用是因为 ${$VAL} -> \${$VAL}形式存在；
eval export ${NO_EXPORT:+-n} -- "${1}=\${CONFIG_${2}_${3}:-\${4}}"
export ${NO_EXPORT:+-n} "$1=$_tmp"
export ${NO_EXPORT:+-n} "CONFIG_${CONFIG_SECTION}_${varname}=$value" 

debug () {  #如果DEBUG不为空，则debug输出值为输入值；否则debug输出值为空
    ${DEBUG:-:} "$@"  # ${DEBUG:-:} 可以返回 ':', 放在命令前表示注释
} 
    
注意：设置新绑定时,pthread_setspecific()不会释放其存储空间。必须释放现有绑定,否则会出现内存泄漏。
pthread_key_t key是全局变量。
    同一个键值可以由多个线程所共享。某一个线程调用pthread_key_create创建一个键，其他线程都可以使用这个键。
这样，不同的线程使用同一个键值，调用pthread_getspecific(key)函数，会得到不同的值。
如果一个线程想拥有多个不同的线程私有数据，那么就应该申请多几个键值。
    
    进程组是为了信号传递这样的目的而建立的进程集合。比如说，在终端运行一个进程，这个进程fork了一个子进程。
当我们在终端输入Ctrl+C。那么父进程和子进程都会收到这个中断信号，信号在这个进程组里面传递了。又比如说函数
kill(pid_ t pid, int signo)。当pid为负数时，表示向一个进程组发送信号。
    会话是为了作业控制而建立的一个进程组集合(注意，进程组是进程的集合)。一个控制终端只与一个会话有关，
一个会话中可能会有多个进程组，但任一时刻，只有一个进程组拥有控制终端(即可以从控制终端获取输入和输出到控制终端)，
拥有控制终端的进程称为前台进程组，其余的进程组称为后台进程。
    作业控制的主要目的是控制哪个进程组拥有控制终端。
注意，有些系统并不支持作业控制。
    
    
    
1. 相对路径包含头文件: 弊端 
#include    "function/head.h"
当function目录改成其它名字，或者head.h文件放到其它目录了，这时都要对main.cpp文件进行修改，
如果head.h头文件被很多其它文件包含的话，这个工作量就大多了。
g++ main.cpp function/head.cpp -o main
2. 用编译选项 –I(大写i)
g++ main.cpp function/head.cpp -Ifunction -o main
用-I选项，相当于说明了一条标准路径。
3. 使用.o文件
g++ -c function/head.cpp -o function/head.o
mv head.o ../
g++ -c main.cpp -Ifunction -o main.o  # 编译命令
g++ main.o head.o -o main             # 链接命令
4. 静态库
g++ -c sub.cpp add.cpp
ar -cr libhead.a add.o sub.o
g++ main.cpp -Ifunction -Lfunction -lhead -o main
-L表示要使用的静态库的目录。
可能-L所指明的目录下有很多静态库，所以除了要告诉去哪里找之外，还要告诉编译器，找哪一个静态库。
此时，就要用到-l(小写L)了。它用来说明链接的时候要用到哪个静态库。
注意：
  1. 注意是使用-lhead,而不是-llibhead
  2. 要把-l放到命令的尽可能后的位置，必须放到源文件的后面。
5. 动态库
$g++ -c -fPIC add.cpp sub.cpp
$g++ -shared -fPIC add.o sub.o -o libhead.so 
$g++ -Ifunction -Lfunction -lhead main.cpp -o main
./main: error while loading shared libraries: libhead.so: cannot open shared object file: No such file or directory  
环境变量LD_LIBRARY_PATH指定的路径
缓存文件/etc/ld.so.cache指定的路径
默认的共享库目录，先是/lib，然后是/usr/lib
运行./main时，明显这三个地方都没有找到。因为我们没有把libhead.so文件放到那里。
g++ -Ifunction ./libhead.so main.cpp -o main
注意:
  1. 在当前目录下查找libhead.so动态库。注意这个命令不再使用-L 和 -l了
6. 打造自己的库目录和头文件目录
1.指定运行时Linux加载动态库的查找路径
  可以修改环境变量LD_LIBRARY_PATH或者修改/etc/ld.so.cache文件。这里选择修改/etc/ld.so.cache文件。
  1)  创建目录/mylib/so。
  2)  创建并编辑一个mylib.conf文件。输入命令$sudo vim /etc/ld.so.conf.d/mylib.conf
  在mylib.conf文件中输入 /mylib/so 
  3)  重建/etc/ld.so.cache文件。输入命令$sudo ldconfig
  g++  -Ifunction -Lfunction -lhead main.cpp 
2. 指定编译时的头文件路径
  1.先搜索当前目录（使用include””时）
  2.然后搜索-I指定的目录
  3.再搜索环境变量CPLUS_INCLUDE_PATH、 C_INCLUDE_PATH。两者分别是g++、gcc使用的。
  4.最后搜索默认目录 /usr/include  和 /usr/local/include等

~/.bashrc
  C_INCLUDE_PATH=/usr/include/libxml2:/mylib
  export C_INCLUDE_PATH
  CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/include/libxml2:/mylib
  export CPLUS_INCLUDE_PATH

g++ -Lfunction -lhead mian.cpp -o main

3.指定链接时的动态库路径
  需要注意的是，链接时使用动态库和运行时使用动态库是不同的。
  同样先搞清搜索顺序：
  1. 编译命令中-L指定的目录
  2. 环境变量LIBRARY_PATH所指定的目录
  3. 默认目录。/lib、/usr/lib等。

#找到动态链接库的路径
LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/mylib 
export LD_LIBRARY_PATH

#找到静态库的路径
LIBRARY_PATH=$LIBRARY_PATH:/mylib
export LIBRARY_PATH

C语言的locale.txt

https://blog.csdn.net/luotuo44/column/info/memcached-src
https://github.com/programming-book-practice
https://blog.csdn.net/astrotycoon/article/category/1119544


https://github.com/learnbyexample/Linux_command_line
https://github.com/learnbyexample/Command-line-text-processing
https://github.com/learnbyexample/Python_Basics
https://github.com/learnbyexample/py_regular_expressions
    
https://linux.cn/article-10921-1.html
http://www.grymoire.com/Unix/Awk.html#uh-41

http://www.ruanyifeng.com/blog/2019/07/weekly-issue-63.html

https://pythonguidecn.readthedocs.io/zh/latest/


http://www.pythondoc.com/
https://github.com/dunwu/linux-tutorial
https://github.com/best90/learn-python3
https://github.com/TwoWater/Python
https://www.cnblogs.com/f-ck-need-u/p/9832640.html

https://github.com/heqinglian/heqinglian.github.io

胆固醇结晶本身是胆囊所分泌的胆固醇由于溶解度的改变，胆汁中的胆固醇含量超过了胆汁酸和磷脂溶解胆固醇的能力，胆汁中部分胆固醇就不能溶解在胆汁中，就会析出胆固醇结晶而发生沉淀。一般量不多，且能够通过循环排出。大量易形成胆结石。
　　一旦发现胆囊内已经有结晶，要定期复查胆囊B超，一旦发生胆囊结石或胆囊息肉，就应该尽早微创腹腔镜手术治疗。至于做微创保胆取石还是做微创胆囊切除，因人而异。平时要注意合理的饮食：做到“七要”与“五忌”。
　　七要：一要多吃含维生素A的食物，如绿色蔬菜、胡萝卜、番茄、白菜等，平时应多吃些香蕉、苹果等水果。二要用植物油炒菜，所吃的菜以炖、烩、蒸为主。三要常吃些瘦肉、鸡、鱼、核桃、黑木耳、海带、紫菜等、四要多吃些能促进胆汁分泌和松驰胆道后约肌、有利胆作用的食物如山楂、乌梅、玉米须（泡茶慢慢喝）。五要吃早餐，不可空腹的时间太长。六要经常运动，防止便秘。七要减肥。
　　五忌：一忌胆固醇较高的食物，如动物心、肝、脑、肠以及蛋黄、松花蛋、鱼子及巧克力等。二忌高脂肪食物，如肥肉、猪油、油炸食品，油多的糕点也不宜多吃，因为过多的脂肪引起胆囊收缩，导致疼痛。三忌节假日或亲友聚会时大吃大喝。因为暴饮暴食会促使胆汁大量分泌，而胆囊强烈的收缩又会引起胆囊发炎、局部绞痛等。四忌食辛辣刺激的调味品，如辣椒、胡椒等。五忌烟、酒、咖啡等，这些带有刺激性的食品会使胃酸过多，胆囊剧烈收缴而导致胆道口括约肌痉挛、胆汁排出困难，易诱发胆绞痛。


------ ------ 说明token分类，有利于理解脚本
标识符=操作符+单词              token=operator+word
token：被shell作为单个单元的一串字符。是一个word或者operator
operator：包括控制操作符(control operator)和重定向操作符(redirection operator)。
          operator至少要包括一个未被引用的元字符(metacharacter)
word：被shell作为单个单元的一串字符。words不包括未被引用的元字符
操作符=控制操作符+重定向操作符  operator=(control operator)+(redirection operator)
control operator：起控制作用的token，包括换行和 || && & ; ;; | |& ( )字符
redirection operator: 见 redirection 部分 

单词=元字符+名称+保留字         word=matecharacter+name+(reserved word)
matecharacter：未被引用的元字符用来分隔words。元字符包括tab 空格 换行和| & ; ( ) < >字符
name：一个只包含字母数字下划线并且以字母或者下划线开始的word。name用来标示变量或者函数名，或者说是一个标识符
reserved word：对shell有特殊意义的word。大部分保留字开始一个控制流程，比如for或者while
------ ------

${}   {}        参数扩展   大括号扩展|命令组|函数
$[]   []        数值计算   test判断
$()   ()        命令替换   命令组
$(()) (())      计算扩展   ((算术表达式))
      [[]]                  bash 支持 pattern 和 regular 匹配命令
>     >(list)   输出重定向  进程替换
<     <(list)   输入重定向  进程替换
如果使用>(list)，往这个文件（描述符）写数据会作为list的标准输入；
<(list)表示将list的标准输出作为command的标准输入。
注意><和后面的括号之间不能有空格

1. 内置命令都接受以-开始的选项并且以--表示选项的结束。
2. true false test内置命令不接受任何参数同时也不会对--特殊对待
3. exit、logout、break、continue、let和shift命令接收-开始的参数，但是不需要--来表示选项的结束。
4. : 的任何参数都会被忽略掉，同时直接返回 0 

[[ $s = 'something' ]] && echo 'matched' || echo "didn't match"
[[ $s == 'something' ]] && echo 'matched' || echo "didn't match"
[[ $s != 'something' ]] && echo "didn't match" || echo "matched"
[[ $s -eq 10 ]] && echo 'equal' || echo "not equal"
(( $s == 10 )) && echo 'equal' || echo 'not equal'

command && echo 'exited with 0' || echo 'non 0 exit'
cmd && cmd1 && echo 'previous cmds were successful' || echo 'one of them failed'
cmd || cmd1 #If cmd fails try cmd1

cd my_directory && pwd || echo "No such directory"
cd my_directory && ls || echo "No such directory"

[ "$?" -eq 0 ] && success $"$base startup" || failure $"$base startup" 
[ "$RC" -eq 0 ] && failure $"$base shutdown" || success $"$base shutdown"
"$@" && success $"$STRING" || failure $"$STRING"

[ a = b ] && { echo "let me see."
               echo "hmmm, yes, i think it is true" ; } \
          || { echo "as i am in the negation i think "
               echo "this is false. a is a not b."  ; }

2、判断字符串 # 1.未初始化、2.初始化为空、3.初始化为空格、4.初始化非空格
test –n 字符串                    字符串的长度非零
test –z 字符串                    字符串的长度为零
[[ -n "$string" ]];          "$string is non-empty"   # 初始化非空
[[ -z "${string// }" ]];     "$string is empty or contains only spaces" # 初始化非空 且 非空格
[[ -z "$string" ]];          "$string is empty"       # 初始化为空
[[ -n "${string+x}" ]];      "$string is set, possibly to the empty string" # 
[[ -n "${string-x}" ]];      "$string is either unset or set to a non-empty string" # 
[[ -z "${string+x}" ]];      "$string is unset" # 
[[ -z "${string-x}" ]];      "$string is set to an empty string" # 
+-----------------------+-------+-------+-----------+
$string is:             | unset | empty | non-empty |
+-----------------------+-------+-------+-----------+
| [[ -z ${string} ]]    | true  | true  | false     |
| [[ -z ${string+x} ]]  | true  | false | false     |
| [[ -z ${string-x} ]]  | false | true  | false     |
| [[ -n ${string} ]]    | false | false | true      |
| [[ -n ${string+x} ]]  | false | true  | true      |
| [[ -n ${string-x} ]]  | true  | false | true      |
+-----------------------+-------+-------+-----------+

case ${var+x$var} in
  (x) echo empty;;                     # 初始化为空
  ("") echo unset;;                    # 未初始化
  (x*[![:blank:]]*) echo non-blank;;   # 初始化非空格
  (*) echo blank                       # 初始化为空格
esac

# 字符串比较需要使用 " " 双引号
test 字符串1=字符串2              字符串相等
test 字符串1!=字符串2            字符串不等
[ "$string1" == "$string2" ]
[ "$string1" != "$string2" ]
# 模式匹配，支持*?[]方式匹配
[[ "$string" == $pattern1 ]]
[[ "$string" != $pattern1 ]]
# 字符串判断只有 == = != > < 几种操作符，不支持 >=或者 <= 这两个操作符

# broken link 1. 链接文件存在，2. 链接文件是断链文件、3. 链接文件是非断链文件
[[ -L $filename || -e $filename ]]  "$filename exists (but may be a broken symbolic link)"
[[ -L $filename && ! -e $filename ]] "$filename is a broken symbolic link"

calculation='2 * 3'
echo "$calculation"         # prints 2 * 3
echo $calculation           # prints 2, the list of files in the current directory, and 3
echo "$(($calculation))"    # prints 6

echo "$var"             # good
echo "$(mycommand)"     # good
another=$var            # also works, assignment is implicitly double-quoted
make -D THING=$var      # BAD! This is not a bash assignment.
make -D THING="$var"    # good
make -D "THING=$var"    # also good

"${STRING}$(command)" 进行 变量扩展、历史扩展、命令替换; 引用可以禁用对特殊字符的特殊对待，参数扩展
${STRING}$(command)   进行 模式匹配、大括号扩展、波浪号扩展、变量扩展。用于扩展和 模式比较、正则表达式比较
$VAR 首先得到VAR对应的值，然手使用空格对各部分进行分割，最后，按照全局匹配解释被分割的各部分

comm compare two sorted files line by line
cmp  compare two files byte by byte
diff compare files line by line

在[[]] 中 < > 只能用于比较字符串，不能用于比较数字，
在[] [[]] 中比较数字都可以用 lt le eq ne gt ge。 在[]中比较数字也可以使用 < >
 ((...)) 可以使用C-style方式进行数值比较

sudo -s <<EOF
  a='var'
  echo 'Running serveral commands with sudo'
  mktemp -d
  echo "\$a"
EOF

sudo -s <<'EOF'
  a='var'
  echo 'Running serveral commands with sudo'
  mktemp -d
  echo "$a"
EOF

ssh -p 21 example@example.com <<EOF
  echo 'printing pwd'
  echo "\$(pwd)"
  ls -a
  find '*.txt'
EOF

ssh -p 21 example@example.com <<'EOF'
  echo 'printing pwd'
  echo "$(pwd)"
  ls -a
  find '*.txt'
EOF

cat << EOF > foo.sh 
printf "%s was here" "$name" 
EOF
cat >> foo.sh <<EOF 
printf "%s was here" "$name"
EOF

AUT_RLOSS=`echo "$AUT_RLOSS*1000" | bc`
MXTICS=`echo "$SMPINF_PRECISION*100" | bc`

gnuplot << EOF
set terminal png size 1024,768
set output "$1.png"
set title "curvedata (distance:$STP_DISTANCE_VAL pluse:$STP_PLUSE_VAL wavelen:$WLS_VAL avgs:$ALA_VAL ior:$IOR_VAL sample:$SMPINF_SAMPLES total length:$AUT_LEN)"
set xlabel "samples total length:$AUT_LEN loss:$AUT_LOSS rloss:$AUT_RLOSS"
set ylabel "dB (dB/1000)"
set yrange [ 0 : $AUT_RLOSS ]
plot "$1" using 1:2 title "curvedata" with lines
EOF

ftp -i -n<<EOF
open 192.168.27.253
user root 123456
cd /etc/rtud
lcd /etc/rtud
binary
prompt
get serial
prompt
close
bye
EOF

wget ftp://192.168.27.253:/etc/rtud/* --user=root --password=123456

FTILE_NAME=$1
ftp -n <<- EOF
open 10.10.21.103
user user 123
cd test
bin
put $FTILE_NAME
bye
EOF

Here document  <<EOF   <<-EOF  <<'EOF'  <<\EOL # 1. 执行ftp telnet等命令 2. 创建特定文件 3. 本地输出
Here String    <<<"$string"
Redirection    < file
process substitution    <(命令列表)
comamnd substitution    $(command)

bc
echo '2 + 3' | bc
echo '12 / 5' | bc
echo '12 / 5' | bc -l
echo '8 > 5' | bc
echo '10 == 11' | bc
echo '10 == 10 && 8 > 3' | bc

dc
支持浮点运算
echo '2 3 + p' | dc
dc <<< '2 3 + p'
dc <<< '1 1 + p 2 + p'
dc <<< '_1 p'
dc <<< 'A.4 p'
c 清除压栈 d 复制栈顶的值 p 输出栈顶值 q 退出交互模式

dc <<< '4 3 / p'
dc <<< '2k 4 3 / p'
dc <<< '4k 4 3 / p'

dc << EOF
1 1 +
3 *
p
EOF

1. let
let num=1+2        # right
let num="1+2"      # right
let 'num= 1 + 2'   # right
let num=1 num+=2   # right
                  
let num = 1 + 2    #wrong
let 'num = 1 + 2'  #right
let a[1] = 1 + 1   #wrong
let 'a[1] = 1 + 1' #right

2. (())
((a=$a+1))     #add 1 to a
((a = a + 1))  #like above
((a += 1))     #like above
if (( a > 1 )); then echo "a is greater than 1"; fi
result=$((a + 1))
echo "The result of a + 1 is $((a + 1))"

3. expr
expr 6 + 3    # 9
expr 2 \* 3   # 6  (有转义符号)
a=3
expr $a+5     # 3+5(无空格)
expr $a + 5   # 8 (有空格)

compgen -b | column

scoping
$ x=3
$ func1 () { echo "in func1: $x"; }
$ func2 () { local x=9; func1; }
$ func2
in func1: 9
$ func1
in func1: 3


diff <(curl http://www.example.com/page1) <(curl http://www.example.com/page2)

while IFS=":" read -r user _
do
    # "$user" holds the username in /etc/passwd
done < <(grep "hello" /etc/passwd)

<(grep "hello" /etc/passwd) 产生一个输出流，
< 将输出流绑定到输入流上

cat header.txt body.txt >body.txt # >先将body.txt截断，然后将header.txt body.txt的内容写入body.txt
cat header.txt <(cat body.txt) > body.txt # 先执行<(cat body.txt)将数据缓存到缓冲中，然后截断body.txt，最后将cat

a='I am a simple string with digits 1234'
pat='(.*) ([0-9]+)'
[[ "$a" =~ $pat ]]
echo "${BASH_REMATCH[0]}"
echo "${BASH_REMATCH[1]}"
echo "${BASH_REMATCH[2]}"

date=20150624
[[ $date =~ ^[0-9]{8}$ ]] && echo "yes" || echo "no"
date=hello
[[ $date =~ ^[0-9]{8}$ ]] && echo "yes" || echo "no"


$ mkdir globbing
$ cd globbing
$ mkdir -p folder/{sub,another}folder/content/deepfolder/
touch macy stacy tracy "file with space" folder/{sub,another}folder/content/deepfolder/file
.hiddenfile
$ shopt -u nullglob
$ shopt -u failglob
$ shopt -u dotglob
$ shopt -u nocaseglob
$ shopt -u extglob
$ shopt -u globstar

$ echo no*match
no*match

$ shopt -s nullglob
$ echo no*match
$

$ shopt -s failglob
$ echo no*match
bash: no match: no*match
$
failglob > nullgolb 

shopt -s globstar
echo *   # 显示本目录
echo **  # 显示本目录和子目录

shopt -s extglob
?(pattern-list) – Matches zero or one occurrence of the given patterns
*(pattern-list) – Matches zero or more occurrences of the given patterns
+(pattern-list) – Matches one or more occurrences of the given patterns
@(pattern-list) – Matches one of the given patterns
!(pattern-list) – Matches anything except one of the given patterns
$ echo *([r-t])acy
stacy tracy
$ echo *([r-t]|m)acy
macy stacy tracy
$ echo ?([a-z])acy
macy


#!/bin/bash
FILENAME="/etc/passwd"
while IFS=: read -r username password userid groupid comment homedir cmdshell
do
  echo "$username, $userid, $comment $homedir"
done < $FILENAM

parameter expansion, command substitution, variable or arithmetic expansion,
    shell扫描parameter expansion command substitution和arithmetic expansion的结果进行word splitting，如果结果包
含在双引号中则不进行word splitting
    Shell将$IFS的每一个字符作为分隔符，使用分隔符将其他扩展的结果分隔为单个的word。如果IFS未设置，或者它
的值就是<space>  <tab>  <newline>这些默认值，则扩展结果中的开始的和结束的一串默认分隔符都被忽略，其他
位置的一串默认分隔符用来分隔操作。如果IFS非默认值，则扩展结果中开始和结束的一连串的空格和tab也被忽
略，就像空格字符也在$IFS中一样。IFS中的其他字符用来作为word splitting的分隔符。一系列的空格也被当做是一
个分隔符。如果IFS为空值，则不进行word splitting

set -x
var='I am
a
multiline string'
fun() {
    echo "-$1-"
    echo "*$2*"
    echo ".$3."
}
fun $var # fun I am a multiline string

set -x
var='I am
a
multiline string'
IFS=' '
fun() {
    echo "-$1-"
    echo "*$2*"
    echo ".$3."
}
fun $var
fun I 'am
a
multiline' string

IFS=$'\n'
fun 'I am' a 'multiline string'

IFS=
fun 'I am
a
multiline string'

$ a='I am a string with spaces'
$ [ $a = $a ] || echo "didn't match"
bash: [: too many arguments
didnot match

[ $a = something ] || echo "didn't match"

Looping through space separated words:
words='foo bar baz'
for w in $words;do
    echo "W: $w"
done

packs='apache2 php php-mbstring php-mysql'
sudo apt-get install $packs

packs='
apache2
php
php-mbstring
php-mysql
'
sudo apt-get install $packs

# showarg
#!/usr/bin/env bash
printf "%d args:" $#
printf " <%s>" "$@"
echo

var="This is an example"
showarg $var
4 args: <This> <is> <an> <example>

var="This/is/an/example"
showarg $var
1 args: <This/is/an/example>

IFS=/
var="This/is/an/example"
showarg $var
args: <This> <is> <an> <example>

    bash中有四个重要且不易区分的概念；
      文件名(特殊字符串)，字符串，管道(流对象,表示已打开文件, 需要指定描述符名称)，重定向(包括打开文件的过程,需要指定文件名)。
    1. 文件名       sed awk cut tr wc等命令参数
    2. 字符串       $(command)
    3. 管道(流对象) <(命令列表) >(命令列表)mkfifo fifo 
    4. 重定向       > >> &> (流与流、流与文件、流与命令 之间关系) < <<[-]EOF <<<"$string" | &|
    <(命令列表) >(命令列表) 命令列表和外界通过命名管道进行通信。'进程替换'的执行结果是 /dev/fd/62和/dev/fd/63, 
因此，可以把执行结果看做是 命名管道文件。可以通过重定向输入或输出到bash设定流目的地。
    <<< 将字符串的内容放到bash的输入缓冲区中，允许read命令，awk命令读取输入缓冲区，处理bash缓冲内字符串数据。
    <<[-]EOF 将字符串内容重定向到cat ftp ssh sudo等命令的输入缓冲区中， 默认输入目的地 不是标准输入，不能应用到read
    $(命令)  将命令的执行结果作为字符串.

单词分割
1. shell扫描参数扩展、命令替换和算术扩展 之后进行 单词分割，如果结果包含在双引号中则不进行单词分割。
2. shell将$IFS的每一个字符作为分隔符，使用分隔符将其他扩展的结果分隔为单个的word。
3. 如果IFS未设置，或者它的值就是<space> <tab> <newline>这些默认值，
   则扩展结果中的开始的和结束的一串默认分隔符都被忽略，其他位置的一串默认分隔符用来分隔操作。
4. 如果IFS非默认值，则扩展结果中开始和结束的一连串的空格和tab也被忽略，就像空格字符也在$IFS中一样。
   IFS中的其他字符用来作为 单词分割 的分隔符。一系列的空格也被当做是一个分隔符。
5. 如果IFS为空值，则不进行 单词分割. 显式的给IFS赋空值(""或者'')，则IFS为空值。

    什么时候避免使用单词拆分(如何避免单词拆分功能生效)，什么时候使用单词拆分
(如何使用单词拆分功能，在哪些情况下单词拆分生效)。进一步，需要考虑什么时候使用
大括号扩展(大括号扩展如何生效)，如何避免大括号扩展生效，波浪号扩展、shell参数扩展
命令替换、算术扩展、进程替换和单词拆分。如何生效和如何无效的考虑？什么时候使用和如何使用
的问题。是bash编程的难点。
    shell扩展存在表象和实质的差异，形式化的表象 在扩展后，就是留给bash的实质内容，
    又如，if else 和 && || 之间使用场景的差异和共同点。

while read line || [ -n "$line" ] ; do echo "line $line" ; done < file.txt # 防止文件内容未读完。
    
string='Question%20-%20%22how%20do%20I%20decode%20a%20percent%20encoded%20string%3F%22%0AAnswer%20%20%20-%20Use%20printf%20%3A)'
printf '%b\n' "${string//%/\\x}"
# Question - "how do I decode a percent encoded string?"
# Answer   - Use printf :)

echo "http%3A%2F%2Fwww.foo.com%2Findex.php%3Fid%3Dqwerty" | sed -e "s/%\([0-9A-F][0-9A-F]\)/\\\\\x\1/g" | xargs -0 echo -e

case $argument in
d) debug_level=$OPTARG ;;
\?) echo "Usage: ./test2.sh -d debug_level"
  exit 1
  ;;
esac

面向语言中类型的判断，正则表达式最实用，可以使用 [[]] case awk sed grep等等

当程序打开此文件是，Linux会自动将它重定向到一个终端窗口，因此该文件对于读取人工输入时特别有用。见如下Shell代码：
/> vi test_dev_tty.sh

#!/bin/bash
printf "Enter new password: "   #提示输入
stty -echo                      #关闭自动打印输入字符的功能
read password < /dev/tty        #读取密码
printf "\nEnter again: "        #换行后提示再输入一次
read password2 < /dev/tty       #再读取一次以确认
printf "\n"                     #换行
stty echo                       #记着打开自动打印输入字符的功能
echo "Password = " $password    #输出读入变量
echo "Password2 = " $password2
echo "All Done"


STRING="hello"
string="world"
cat <<<${STRING} <<<${string}  # world
cat <<<${STRING} <<<${string} <<<${STRING} # hello
cat <<<${STRING} <<-EOF
beijing
EOF
# beijing
dc <<< '4k 4 3 / p' # 1.3333
dc << EOF
> 1 1 +
> 3 *
> p
> EOF
# 6

---- 恰如其分的使用bash提供的功能 ----
什么时候应当避免单词拆分(如何避免单词拆分的功能); 什么时候进行单词拆分(如何使用单词拆分的功能)
进一步, 什么时候避免使用大括号扩展(如何避免大括号扩展功能)，什么时候使用大括号扩展(如何使用大括号
扩展功能); 波浪号扩展功能的避免和使用，shell参数扩展的避免和使用，命令替换的避免和使用,进程替换的
避免和使用，文件名扩展的避免和使用。
如何使用 '[[]]' 的模式匹配和正则表达式匹配; 
如何使用 <<<(here string) 和<<(here document) 和 输入输出重定向功能；以及命名管道的功能；进程替换
区分 let 和 expr 两种表达方式。 let的参数是表达式，而expr的参数是表达式中的变量和操作符。
export local typeset declare alias的参数表达形式，每个赋值语句作为一个参数看待
command1 && success || failure 根据前驱命令状态决定后继命令执行; 
                               将前驱命令返回状态，转换成成功和失败的信息输出。(将返回值状态转换成字符串输出)
[ $? = 0 ] && success || failure 程序的输出内容和程序的返回状态分离，程序的返回状态决定后续命令的执行。
                                 字符串分析和返回值双重分析。
字符串有: 未初始化,初始化为空,初始化为空白字符,和初始化为非空白字符四种状态。
字符串有: "${string}" '${string}' $'string' 和 $string 四种形式。常用"${string}"
IFS对单词拆分和read命令的影响。
变量和函数的动态作用域范围: 变量引用是以变量被解引用运行时所在作用域进行解引用，而不是以变量定义时所在作用域进行解引用。
通过printf "%s\n" * ; printf "%s\n" */ ; printf "%s\n" *.{gif,png,jpg} 
set -euo pipefail 以及 trap 信号捕获的使用。又何时 $(resolve_link "$name" || true) 通过true去除 -e 捕获; 当然此时没有pipefail
case *?[]构成的模式匹配和 [[]]和BASH_REMATCH sed awk egrep 实现的正在表达式匹配，用于处理符合特定格式"类型" 的匹配
命令行处理时 getopt while for shift OPTARG OPTINT
${string:offset:length} 在命令行参数、函数参数和字符串、数组各种形式下的差异
token=operator + word
  operator=(control operator) + (redirection operator)
  word=name + (reserved word)
哲学: 爱使它们结合;恨使它们分离. bash 编程就是需要考虑: 如何用爱使它们结合，使得用恰如其份的结合方式实现恰如其份的功能
      bash各种扩展前是一种语言实现，bash各种扩展后是一种语言实现。扩展有模式功能、系统功能、字符串处理功能和bash自身功能。
模式功能有:大括号扩展和模式匹配；系统功能有命令替换、进程替换和波浪号扩展；字符串处理功能有参数扩展；bash自身功能有单词拆分。
扩展功能可是视作bash提供的API。
  扩展前的世界是现实的世界，扩展后的世界是理想的世界。设计的目的是: 让现实的世界更可读，让理想的世界更高效。哲学就是两个世界的折中。

定义1：控制操作符(Control Operator)前面提到元字符是为了把一个字符串分割为多个子串，
       而控制操作符就是为了把一系列的字符串分割成多个命令。
       || & && | ; ;; ( ) |& <newline>
定义2：关键字(Reserved Words) 在 Bash 中，只有 22 个关键字，它们是"! case coproc 
       do done elif else esac fi for function if in select then until while { } time [[ ]]"。
       这其中有不少的特别之处，比如'! { } [[ ]]'等符号都是关键字，也就是说它们当关键字
       使用时相当于一个单词，也就是说它们和别的单词必须以元字符分开(否则无法成为独立的单词)。
"="是一个很变态的特例，因为它既不是元字符，也不是控制操作符，更加不是关键字，它到底是什么？


# 简单创建数据表
sqlite> CREATE TABLE testtable (first_col integer);   # 最简单的数据表
sqlite> CREATE TABLE testtable (first_col integer DEFAULT 0, second_col varchar DEFAULT 'hello'); # 创建带有缺省值的数据表：
# 在指定数据库创建表：
sqlite> ATTACH DATABASE 'd:/mydb.db' AS mydb;
sqlite> CREATE TABLE mydb.testtable (first_col integer);
# 创建两个表，一个临时表和普通表。
sqlite> CREATE TEMP TABLE temptable(first_col integer);
sqlite> CREATE TABLE testtable (first_col integer);
# 将当前连接中的缓存数据导出到本地文件，同时退出当前连接。
sqlite>.backup d:/mydb.db 
sqlite>.exit
sqlite>.restore d:/mydb.db # 重新建立sqlite的连接，并将刚刚导出的数据库作为主库重新导入。
sqlite>.tables # 查看该数据库中的表信息
# "IF NOT EXISTS"从句：
sqlite> CREATE TABLE IF NOT EXISTS testtable (first_col integer);
# CREATE TABLE ... AS SELECT：
    通过该方式创建的数据表将与SELECT查询返回的结果集具有相同的schema信息，但是不包含
缺省值和主键等约束信息。然而新创建的表将会包含结果集返回的所有数据。
sqlite> CREATE TABLE testtable2 AS SELECT * FROM testtable;    
sqlite> .schema testtable2
CREATE TABLE testtable2(first_col INT);
.schema命令是sqlite3命令行工具的内置命令，用于显示当前数据表的CREATE TABLE语句。
# 主键约束
sqlite> CREATE TABLE testtable (first_col integer PRIMARY KEY ASC); # 直接在字段的定义上指定主键。
sqlite> CREATE TABLE testtable2 (
       ...>     first_col integer,
       ...>     second_col integer,
       ...>     PRIMARY KEY (first_col,second_col)
       ...> );  # 
# 唯一性约束
CREATE TABLE testtable (first_col integer UNIQUE);  # 直接在字段的定义上指定唯一性约束。
sqlite> CREATE TABLE testtable2 (
       ...>     first_col integer,
       ...>     second_col integer,
       ...>     UNIQUE (first_col,second_col)
       ...> ); 
在SQLite中，NULL值被视为和其他任何值都是不同的，这样包括和其他的NULL值，即 NULL不受唯一性约束限制
# 为空(NOT NULL)约束：
CREATE TABLE testtable(first_col integer NOT NULL);
# 检查性约束：
CREATE TABLE testtable (first_col integer CHECK (first_col < 5));
sqlite> CREATE TABLE testtable2 (
       ...>     first_col integer,
       ...>     second_col integer,
       ...>     CHECK (first_col > 0 AND second_col < 0)
       ...> );

# 表的修改：仅仅是修改表名和添加新字段。
一旦表名被修改后，该表已存在的索引将不会受到影响，然而依赖该表的视图和触发器将不得不重新修改其定义。
ALTER TABLE testtable RENAME TO testtable2; # 修改表名
ALTER TABLE testtable ADD COLUMN second_col integer; # 增加表字段

# 表的删除
DROP TABLE testtable;
DROP TABLE IF EXISTS testtable;

# 创建视图
sqlite> CREATE VIEW testview AS SELECT * FROM testtable WHERE first_col > 100; # 最简单的视图
sqlite> CREATE TEMP VIEW tempview AS SELECT * FROM testtable WHERE first_col > 100;    # 创建临时视图
sqlite> CREATE VIEW IF NOT EXISTS testview AS SELECT * FROM testtable WHERE first_col > 100; # IF NOT EXISTS 从句

# 删除视图
sqlite> DROP VIEW testview;
sqlite> DROP VIEW IF EXISTS testview;
    视图不支持alter修改视图名字和增加列功能；视图和table都是通过.tables指令获得当前库中所有视图和所有表。
视图不支持主键、唯一性、notnull、check约束，视图和table都支持临时性的视图和table功能。
创建表时所使用的"create table  newtab ... as select ... table" 既得到了表定义，也得到了表数据，没有得到表约束。

# 时间
sqlite> SELECT date('now');  # 返回当前日期
sqlite> SELECT date('now','start of month','1 month','-1 day'); # 返回当前月的最后一天。
sqlite> SELECT strftime('%s','now'); # 返回从1970-01-01 00:00:00到当前时间所流经的秒数。
sqlite> SELECT date('now','start of year','+9 months','weekday 2'); # 返回当前年中10月份的第一个星期二是日期。

# 创建索引
sqlite> CREATE INDEX testtable_idx ON testtable(first_col); # 基于某个表的一个字段
sqlite> CREATE INDEX testtable_idx2 ON testtable(first_col ASC,second_col DESC); # 基于某个表的多个字段，
 同时可以指定每个字段的排序规则(升序/降序)
sqlite> CREATE UNIQUE INDEX testtable_idx3 ON testtable(second_col DESC); # 索引规则和数据表的唯一性约束的规则相同，即NULL和任何值都不同
sqlite> .indices testtable

# 删除索引
sqlite> DROP INDEX IF EXISTS testtable_idx;

# 重建索引
    重建索引用于删除已经存在的索引，同时基于其原有的规则重建该索引。这里需要说明的是，
如果在REINDEX语句后面没有给出数据库名，那么当前连接下所有Attached数据库中所有索引都会被重建。
如果指定了数据库名和表名，那么该表中的所有索引都会被重建，
如果只是指定索引名，那么当前数据库的指定索引被重建。
sqlite> REINDEX; # 当前连接attached所有数据库中的索引都被重建。
sqlite> REINDEX testtable; # 重建当前主数据库中testtable表的所有索引。
sqlite> REINDEX testtable_idx2; # 重建当前主数据库中名称为testtable_idx2的索引。
    
# 数据清理 - 近似于磁盘整理
sqlite> VACUUM;

Attach数据库：
ATTACH DATABASE语句添加另外一个数据库文件到当前的连接中，
如果文件名为":memory:"，我们可以将其视为内存数据库，内存数据库无法持久化到磁盘文件上。
如果操作Attached数据库中的表，则需要在表名前加数据库名，如dbname.table_name。最后需要说明的是，
如果一个事务包含多个Attached数据库操作，那么该事务仍然是原子的。
sqlite> CREATE TABLE testtable (first_col integer);
sqlite> INSERT INTO testtable VALUES(1);
sqlite> .backup 'D:/mydb.db'   --将当前连接中的主数据库备份到指定文件。
sqlite> .exit
--重新登录sqlite命令行工具：
sqlite> CREATE TABLE testtable (first_col integer);
sqlite> INSERT INTO testtable VALUES(2);
sqlite> INSERT INTO testtable VALUES(1);
sqlite> ATTACH DATABASE 'D:/mydb.db' AS mydb;    
sqlite> SELECT t1.first_col FROM testtable t1, mydb.testtable t2 WHERE t.first_col = t2.first_col;

Detach数据库：
卸载将当前连接中的指定数据库，注意main和temp数据库无法被卸载。    
事务：
    在SQLite中，如果没有为当前的SQL命令(SELECT除外)显示的指定事务，那么SQLite会自动为该操作添加一个隐式的事务，
以保证该操作的原子性和一致性。
sqlite> BEGIN TRANSACTION;
sqlite> COMMIT TRANSACTION;

sqlite> BEGIN TRANSACTION;
sqlite> ROLLBACK TRANSACTION;
    
    
命令名 	            命令说明
.help 	             | 列出所有内置命令。
.backup DBNAME FILE  | 备份指定的数据库到指定的文件，缺省为当前连接的main数据库。
.databases 	         | 列出当前连接中所有attached数据库名和文件名。
.dump TABLENAME ...  | 以SQL文本的格式DUMP当前连接的main数据库，如果指定了表名，则只是DUMP和表名匹配的数据表。参数TABLENAME支持LIKE表达式支持的通配符。
.echo ON|OFF 	     | 打开或关闭显示输出。
.exit 	             | 退出当前程序。
.explain ON|OFF 	 | 打开或关闭当前连接的SELECT输出到Human Readable形式。
.header(s) ON|OFF 	 | 在显示SELECT结果时，是否显示列的标题。
.import FILE TABLE 	 | 导入指定文件的数据到指定表。
.indices TABLENAME 	 | 显示所有索引的名字，如果指定表名，则仅仅显示匹配该表名的数据表的索引，参数TABLENAME支持LIKE表达式支持的通配符。
.log FILE|off  	     | 打开或关闭日志功能，FILE可以为标准输出stdout，或标准错误输出stderr。
.mode MODE TABLENAME | 设置输出模式，这里最为常用的模式是column模式，使SELECT输出列左对齐显示。
.nullvalue STRING  	 | 使用指定的字符串代替NULL值的显示。
.output FILENAME  	 | 将当前命令的所有输出重定向到指定的文件。
.output stdout  	 | 将当前命令的所有输出重定向到标准输出(屏幕)。
.quit  	             | 退出当前程序。 
.read FILENAME  	 | 执行指定文件内的SQL语句。
.restore DBNAME FILE | 从指定的文件还原数据库，缺省为main数据库，此时也可以指定其它数据库名，被指定的数据库成为当前连接的attached数据库。
.schema TABLENAME 	 | 显示数据表的创建语句，如果指定表名，则仅仅显示匹配该表名的数据表创建语句，参数TABLENAME支持LIKE表达式支持的通配符。
.separator STRING 	 | 改变输出模式和.import的字段间分隔符。
.show 	             | 显示各种设置的当前值。
.tables TABLENAME 	 | 列出当前连接中main数据库的所有表名，如果指定表名，则仅仅显示匹配该表名的数据表名称，参数TABLENAME支持LIKE表达式支持的通配符。
.width NUM1 NUM2 ... | 在MODE为column时，设置各个字段的宽度，注意：该命令的参数顺序表示字段输出的顺序。

# 固定精度和刻度十进制数 DECIMAL 和 NUMBERIC 等价
DECIMAL ( precision [ , scale] )
NUMERIC ( precision [ , scale] )
SELECT CAST(123 AS DECIMAL(5,2))       --returns 123.00
SELECT CAST(12345.12 AS NUMERIC(10,5)) --returns 12345.12000

# 通常情况下， FLOAT 和 REAL 几乎通用
SELECT CAST(123 AS FLOAT)       --returns 123.00
SELECT CAST(12345.12 AS DEAL)   --returns 12345.12000

# Integer
Data       Range Storage
bigint     8 Bytes
int        4 Bytes
smallint   2 Bytes
tinyint    1 Byte

# 钱币
Data        Range Storage
money       8 bytes
smallmoney  4 bytes

#二进制 固定长度和可变长度
BINARY [ ( n_bytes ) ]
VARBINARY [ ( n_bytes | max ) ]
SELECT CAST(12345 AS BINARY(10))    -- 0x00000000000000003039   -- 12345
SELECT CAST(12345 AS VARBINARY(10)) -- 0x00003039               -- 12345

#CHAR  固定长度和可变长度
CHAR [ ( n_chars ) ]
VARCHAR [ ( n_chars ) ]
SELECT CAST('ABC' AS CHAR(10)) -- 'ABC                                 -- ABC
SELECT CAST('ABC' AS VARCHAR(10)) -- 'ABC'                             -- ABC
SELECT CAST('ABCDEFGHIJKLMNOPQRSTUVWXYZ' AS CHAR(10))  -- 'ABCDEFGHIJ' -- ABCDEFGHIJKLMNOPQRSTUVWXYZ

# UNICODE 固定长度和可变长度
NCHAR [ ( n_chars ) ]
NVARCHAR [ ( n_chars | MAX ) ]

# UNIQUEIDENTIFIER ?

NULL
1. Filtering for NULL in queries
SELECT * FROM Employees WHERE ManagerId IS NULL ;
SELECT * FROM Employees WHERE ManagerId IS NOT NULL ;
NULL不等于任何值，包括NULL自身。使用 = NULL 或者 <> NULl 常常得到意想不到的结果

2. null 与 创建表
create table nulltable (mycol1 int not null, mycol2 int null);  # 创建null要求和非null要求表
INSERT INTO nulltable (mycol1, mycol2) VALUES (1, NULL) ;       # 成功插入
INSERT INTO nulltable (mycol1, mycol2) VALUES (NULL, 2) ;       # 失败插入
主键是不能为NULL的。
insert into singleprimarytable VALUES(NULL);  # 操作成功，但是没有插入数据

3. null 与 update
UPDATE Employees SET ManagerId = NULL WHERE Id = 4

4. null 与 insert
INSERT INTO Employees
    (Id, FName, LName, PhoneNumber, ManagerId, DepartmentId, Salary, HireDate)
VALUES
    (5, 'Jane', 'Doe', NULL, NULL, 2, 800, '2016-07-22') ;
    
https://blog.csdn.net/iEearth/column/info/15104

https://doc.qt.io/qt-5/reference-overview.html
https://github.com/maicss/PyQt5-Chinese-tutorial/blob/master/SUMMARY.md
https://github.com/Haiou1220/QT_exercise
https://www.cnblogs.com/lixuejian/p/10914410.html 

C:\Qt\Qt5.0.0\5.0.0\msvc2010\bin;
C:\Program Files\Microsoft Visual Studio 10.0\VSTSDB\Deploy;
C:\Program Files\Microsoft Visual Studio 10.0\Common7\IDE\;
C:\Program Files\Microsoft Visual Studio 10.0\VC\BIN;
C:\Program Files\Microsoft Visual Studio 10.0\Common7\Tools;
C:\WINDOWS\Microsoft.NET\Framework\v4.0.30319;
C:\WINDOWS\Microsoft.NET\Framework\v3.5;
C:\Program Files\Microsoft Visual Studio 10.0\VC\VCPackages;
C:\Program Files\HTML Help Workshop;
C:\Program Files\Microsoft SDKs\Windows\v7.0A\bin\NETFX 4.0 Tools;
C:\Program Files\Microsoft SDKs\Windows\v7.0A\bin;C:\Program Files\Mozilla Firefox;
C:\Program Files\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\Program Files\Subversion\bin;C:\Program Files\TortoiseSVN\bin;C:\Program Files\Java\jdk1.6.0_20\bin;C:\Program Files\Java\jdk1.6.0_20\jre\bin;C:\Python27;D:/Program Files/MPICH2/bin;C:\Python27\Scripts;C:\Program Files\doxygen\bin;C:\cygwin\bin;C:\cygwin\sbin;C:\cygwin\usr\bin;
C:\cygwin\usr\sbin;C:\Program Files\Calibre2\;C:\Program Files\Lua\5.1;C:\Program Files\Lua\5.1\clibs

https://github.com/kozross/awesome-c
https://github.com/srdja/Collections-C
    
https://www.docin.com/p-1757815214.html
https://github.com/embest-tech/fsl-linaro-toolchain
https://github.com/cuav?page=1

https://github.com/CyC2018/CS-Notes java
https://github.com/Snailclimb/JavaGuide java
https://github.com/DuGuQiuBai/Java      java

https://www.toolfk.com/tool-online-manual
https://www.cnblogs.com/stephen-liu74/archive/2012/01/13/2321668.html
https://github.com/planetopendata/awesome-sqlite
https://sqlite.org/docs.html
https://sqlite.org/capi3ref.html

  https://www.cnblogs.com/youxia/p/java006.html # 这些年一直记不住的 Java I/O
./ops_doc-master/SQLite学习手册.sh
https://www.cnblogs.com/stephen-liu74/archive/2012/01/09/2309674.html Java C++ SQLite
https://github.com/ab300819/Knowledge Java
https://blog.csdn.net/K346K346/column/info/c-cplusplus C++
https://github.com/EbookFoundation/free-programming-books/blob/master/free-programming-books-zh.md#ide