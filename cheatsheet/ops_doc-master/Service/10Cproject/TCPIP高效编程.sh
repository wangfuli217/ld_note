etcpsrc.zip
one-hour-hack-master.zip

https://huoding.com/2013/12/31/316 # https://huoding.com/2013/12/31/316
https://yq.aliyun.com/articles/4252  # Linux TCP队列相关参数的总结

我认为TCP网络编程有三个例子最值得学习研究，分别是echo、chat、proxy，都是长连接协议。
moduo(){
                我一般会开四个命令行窗口，其一看log，其二看strace，其三用netcat/ 
tempest/ipython充作通信对方，其四看tcpdump。各个工具的输出相互验证，很快就摸清了门道。

TCP作为一个可靠的传输层协议，其核心有三点： 
1.  Positive acknowledgement with retransmission                                    第一点已经足以满足“可靠性”要求
2.  Flow control using sliding window（包括Nagle 算法等）                           第二点是避免发得太慢
3.  Congestion control（包括slow start、congestion avoidance、fast retransmit等）   第三点是避免发得太快

传输层方面，由于链路层带宽大增，TCP window scale option 被普遍使用，另外 TCP timestamps option 和 TCP selective ack option 也很常用。
}

ibm(Linux 套接字编程中的 5 个隐患){
隐患 1．忽略返回状态
隐患 2．对等套接字闭包
隐患 3．地址使用错误（EADDRINUSE）
隐患 4．发送结构化数据
隐患 5．TCP 中的帧同步假定
}

main(){
https://www.kancloud.cn/kancloud/prog-notes/73335#
http://pw1.netcom.com/~jsnader/

http://blog.csdn.net/column/details/high-perf-network.html  # 高性能网络编程
http://blog.csdn.net/column/details/nginx-module-develop.html # nginx 高性能module开发

TCP 只要解决的三个问题：丢包， 重复，延迟
当然，TCP层为了可靠性，还额外需要解决3个大问题：
1. 丢包（网络分组在传输中存在的丢失）、
2. 重复（协议层异常引发的多个相同网络分组）、
3. 延迟（很久后网络分组才到达目的地）。

即使应用程序都运行在同一台机器上，UDP也无法保证任何指定数据报安全到达。
A) 客户端和服务器位于同一台主机上
   A1) 由于没有网络延时，采用这种配置更容易判断客户端和服务器应用程序的原始性能
   A2) 提供了一种理想的实验环境，分组不会被丢弃、延迟，传输时也不会失序
B) 客户端和服务器位于同一个局域网内
   B1) 近乎理想，分组很少丢失，并且实际上从不会出现错序
C) 客户端和服务器位于不同的局域网中
   C1) 随着WAN流量的增加，用来在转发分组之前临时存储分组的路由器队列会被填满。路由器的队列空间耗尽时就开始丢弃分组。
       导致重传，重传又会导致分组的重复和乱序传输。

SOCKET socket(int domain, int type, int protocol);
domain:AF_INET, AF_LOCAL
type: SOCK_STREAM  可靠的、全双工、面相连接的字节流
      SOCK_DGRAM   不可靠，尽力而为的数据报服务
      SOCK_RAW     允许对IP层的某些数据报进行访问
protocol: SOCK_STREAM:0， SOCK_DGRAM:0 SOCK_RAW:需要指定

MSG_OOB        会发送或读取紧急数据
MSG_PEEK       用来查看输入数据，但不会将其从接收缓冲其中删除。执行调用之后，接下来的读操作依然可以读到哪些数据
MSG_DONTROUTE  使内核绕过通常的选路函数。通常只有选路程序使用，或者用于诊断。

INADDR_ANY
listen()唯一任务就是把套接字状态标识为监听状态。
backlog：并不是在指定端口上同时可以建立连接的最大值，而是排队等待应用程序接口的连接或部分连接的最大数量。
         与系统有关，常见指定值大于最大值，自动将其减小为最大值。
注意：两个套接字具有相同的本地端口，但这没有什么问题，因为TCP连接是包括本地地址、本地端口，外部地址和外部端口在内
      的四元祖来完成说明。至少两个套接字的外部地址和端口是不同的，所以内核可以将他们区分开。

gethostbyname，inet_aton，getaddrinfo，getservbyname 输出值都不需要考虑字节序的问题。

tcpserver.skel  tcp_server
tcpclient.skel  tcp_client
udpserver.skel  udp_server
udpclient.skel  udp_client

19 考虑使用两条TCP连接。
24 可能的话，使用一个大规模的写操作，而不是多个小规模的写操作。
   禁用Nagle算法    TCP_NODELAY
   讲写操作合并起来 writev readv mmap
29 不要将IP地址或端口硬编入应用程序中
    绝对不应该将这些参数以硬编码的形式编写到程序中，也不应该将它们放在自己的配置文件中。
    gethostbyname gethostbyaddr
    gethostbyname2
    
    getservbyname getservrbyport
    
}

Stevens 1994 tcp -> Google 
https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE #传输控制协议

TCP单条连接的核心为发送窗口和接收窗口，拥塞窗口，以及序列号。通过查看发送窗口和接收窗口大小，可以确认单条TCP连接的网络性能。

book(面相连接和无连接指的都是协议。术语指的并不是物理介质本身){
    用以说明如何在物理介质上传输数据的。UDP状态是由应用程序，而不是协议来维护的。
                                                   TCP     UDP&IP 一对多和多对一类型协议：
    [维护数据报之间关系]<-[重传、不重复、有序传输] 可靠 VS 不可靠 [不丢失、不延迟、不错序传输]->[独立寻址，数据报之间没有关系]
                                                 有流控     无流控
    
    可靠：接收端主机可能在刚刚对数据进行了ACK，但应用程序还没有将其读走之前，就崩溃了。
          TCP向发送端提供的唯一一个数据接收通知就是这个ACK。发送端应用程序无法从TCP自身判断对等实体应用程序是否真的收到数据了。
    需要显式的请求报文进行响应。一个更难解决的问题是如果服务器没有对收到的报文进行确认，客户端会怎么做？
    可靠：无法保证应用程序A发送的所有数据都会到达。TCP能够向应用程序B保证的是所有到达的数据都是按序且未受损的。
    
    任何健壮的UDP应用程序都必须提供：1. 在合理时间内没有收到应答时，重传请求报文的功能.
                                     2. 确保应答与请求正确匹配。
     RTO定时器。
                                     
    对于无连接来说，每个分组的处理都独立于所有其他分组，而对于面向连接的协议来说，协议实现则维护了与后续分组有关的状态信息。
    
    RTO定时器超时并不意味着原来的数据没有到达目的地，有可能是ACK丢失，或者原来的段在网络中延迟的时间太长，以至于其在ACK到达
之前的RTO超时了，但这并不会造成什么问题，因为如果原来的数据确实到达了，那么重传的数据会处于接收端TCP接收窗口范围之外，会被丢弃。
    
    如果有多个进程或线程打开了这个套接字，那么其中任何一个都可以读取数据，但读过一次之后，数据对其他进程或线程来说就不可用了。
}

ARP(代理){}
BSD(套接字接口比XTI/TLI更好用){
在UNIX中，与TCP/IP这样的通信协议进行接口的API主要有两种：
1. Berkeley套接字
2. XTI（X/Open Transport Interface，X/开放传输接口）

    套接字接口是加州大学伯克利分校为其UNIX操作系统版本开发的。最初在4.2BSD（1983年）上广泛应用，4.3BSD Reno
（1990年）进行了一些改良，现在几乎所有的UNIX版本都提供。其他几种操作系统也提供套接字API。在微软的Windows系统
中广泛使用的Winsock API就起源于BSD套接字API[WinSockgroup, 1997]。

    XTI API是TLI（Transport Layer Interface，传输层接口）的超集，TLI最初是由AT&T在UNIX系统V的版本3.0（SVR3）
中提供的。TLI可以更方便地支持新的协议，从这个意义上来说它的设计是独立于协议的。

BSD API；然后XTI API，最后TLI API
libsocket libxnet     libnsl}

TTCP(){
    Braden对是否需要提供一个介于无连接、不可靠的UDP和面向连接、可靠的TCP协议之间的协议进行了讨论。RFC中的
讨论促使Braden提出了T/TCP（TCP Extensions for Transactions，TCP事务扩展）
    
    既想拥有TCP的可靠性，又要避免连接建立带来的开销，就可以使用T/TCP。它是对TCP的扩展，（通常）会免除TCP在
连接建立阶段使用的三次握手机制，并缩短连接拆除时的TIME-WAIT阶段（技巧22），以此来提供与UDP差不多的事务性能。
Richard Stevens维护的T/TCP主页http://www.kohala.com/start/ttcp.html上有到这些资源及其他T/TCP资源的链接。
}
book(TCP是一种流协议){
    数据是以字节流的形式传递给接收者的，没有固定的报文或者报文边界概念，从这方面来说，读取TCP数据无法预先得知在一次指定的
读调用中会返回多少字节。尽管数据是以IP分组的形式传输的，但分组中的数据量与send调用中传送给TCP多少数据并没有直接关系，而且，
接受程序没有什么可靠的方法可以判断数据是如何分组的，因为在两次recv调用之间可能会有多个分组到来。TCP会记录它发送了多少字节，
但是不会记录这些字节是如何分组的。
    任意指定时刻，可读的数据量都不是确定的。
    基于TCP的通讯程序需要进行封包和拆包.
    TCP协议报文的边界都是由应用程序级维护的。 定长；readn
                                              可变长：
                                              1. 可以用记录结束标记来分割记录；对分隔符进行转义。       readline
                                              2. 在每条报文前加上一个首部，这个首部包含下面的报文长度。 readvrec
                                                 报文长度reclen需要ntohl进行字节序处理
                                               readcrlf
}

book(不要低估TCP的性能){
    通常对网络编程来说，任何协议的性能都与网络、应用程序、负载和包括实现质量在内的其他一些因素有关。了解哪种
协议和算法执行得更好的唯一可信的方法是在与应用程序的运行环境相同的环境中对其进行测试。

    为了提供可靠性，接收端TCP必须向发送端TCP发送ACK。这就增加了两端程序必须处理的内容，但是工作量可能不会有    # ACK
我们预想的那么多。首先，接收端可以通过它要发回给对等实体的数据来捎带ACK。实际上，很多TCP实现都会将ACK延迟几    # ACK
个毫秒发送，以防本端应用程序有对输入分段的应答要发送。第二，TCP没必要为每个段产生一个ACK。正常情况下，大部分   # ACK
TCP实现都是隔一段发送一次ACK的。                                                                               # ACK
    RFC建议延迟发送ACK，但最大不超过0.5秒，并且每两个全尺寸段至少进行一次ACK。                                 
    TCP和UDP之间另一个主要区别在于TCP是个面向连接的协议（技巧1），必须进行连接的建立和拆除。通常情况下，连接   # CONTRACK
的建立需要交换3个段。连接拆除通常需要4个段，但除了最后一个段之外，其他所有段通常都可以和包含数据的段一起传送。 # CONTRACK

    应用程序中仅包含简短的请求/应答会话时，UDP的性能会比TCP好，
    当连接持续的时间很长，并且传输了大量数据时，TCP的性能会比UDP好得多。
    
    为什么客户端指向本地主机时TCP的性能会好那么多，我们用-i选项调用了netstat.
    MTU:1500   网络主机
    MTU:16384  本地主机
    
    block:1440 UDP 优于 TCP  即使本地主机，UDP也存在丢包的情况。防止数据包丢失永远不能忽视。
    block:300  TCP 优于 UDP
    
    不能对TCP和UDP的相对性能做先验假设。条件的改变，即使是看起来很小的改变，都可能对性能指标产生严重影响。
选择使用哪种协议的最佳方法就是用这两种协议测试应用程序，看看它们的性能如何.
}

book(TCP/IP不是轮询的){
    tcp无法将连接的丢失立即通知给应用程序，我们研究为什么TCP不提供这种通知机制，不这么做的优点和缺点，以及应用程序必须完成
哪些工作以检测连接的丢失。

    为什么不轮询，因为轮询都会消耗净荷的网络支援，并且大部分应用程序都不需要即时通知，因此不并为之付出带宽的代价。

    keep-alive（保持活跃）用来检测死链接，应用程序启动保持活跃机制时，TCP会在连接空闲一段时间之后，向对等实体发送一个特殊的段，
如果对等主机可达，且对等程序仍在运行，对等实体会以ACK形式相应，在这种情况下，TCP活跃机制将空闲时间重置为0。如果对等主机可达
但是应用程序没有运行，则对等实体的TCP会以RST响应，TCP发送的保持活跃信号会丢弃连接并相应应用程序返回一个错误。如果对等主机没有
以ACK或RST响应，TCP发送的保持活跃会继续发送保持活跃探测信号，直到它认为对等实体不可达或者崩溃为止。

1. 如果TCP实现了保持活跃机制，在它开始发送保持活跃探测之前，必须有至少2小时的默认空闲时间。
2. BSD实现在放弃连接之前会发送9次探测信号，两次之间间隔75秒。
3. 意味着使用默认设置的BSD派生实现要经过2小时11分15秒才能发现连接已经丢失。
   意识到保持活跃机制试图释放无效连接所持有的资源时，这个值就更有意义了。
4. 有一种新的POSIX套接字选项TCP_KEEPALIVE，这个选项允许在每条连接的基础上指定超时间隔，但并没有得到广泛实现。
}

book(心跳信号){
1. 有一台客户端和一台服务器，它们交互的各种不同类型的报文都有一个用来识别报文类型的首部；
    一种新的报文类型MSG_HEARTBEAT，可以由一端传递给另一端。收到报文MSG_HEARTBEAT时，应用程序只是将报文返回给其对等实体。
这给我们带来较大的灵活性。实际上只有一端发送心跳信号时，连接的一端或两端就都可以通过它来监视连通性了。
2. 有一个应用程序，它为对等实体提供的数据是没有固有记录或报文概念的字节流。
    为心跳报文使用一条独立的连接。用一条连接来监测另一条连接可能会让人觉得很奇怪，但要记住我们是在检测对等实体主机
或某个网络分区是否崩溃了。如果发生此类事件，要么两个连接都会受到影响，要么都不会。
}

FTP(){
    只要在读操作上设置一个定时器，这样的话，如果客户端在某段时间区间内没有发出请求，服务器就假定客户端已经不存在了。
很多FTP服务器就是这么做的：如果客户端在某段时间区间内没有发送任何请求，服务器就放弃连接。用一个显式定时器或者像
心跳实例那样使用select定时器，就可以很方便地解决这个问题。
}

1. 检测客户端的终止
2. 检测无效输入      ：缓冲区溢出和指针丢失- read recv recvfrom readv readmsg

book(成功的LAN策略不一定能推广到WAN中去){
(1) 由于WAN引入了额外的时延，在WAN上的性能可能不尽如人意；
(2) 在LAN上可以工作的不正确代码，在WAN上可能会出现问题。
    WAN上时延的增加会让在LAN上性能良好的应用程序在WAN上的性能不尽如人意。有时就需要对应用程序的设计进行修改。
    在忙碌的WAN，尤其是因特网上出现的拥塞会以无法预料的承载量和次数传送数据。这就要求我们要特别小心，避免对
任何指定时间到达的数据量，及其到达率做任何假设。
}

OSI(){
正如Tanenbaum在[Tanenbaum, 1996]中指出的那样，这个模型最严重的缺陷之一就是它受到了"通信思维"的影响。这种思维方式
反映在术语（与常见的网络用语不同），以及层间接口原语规范上，它更适用于电话系统而不是计算机系统。

}
book(理解TCP的写操作){
    用户程序对一条TCP连接进行写调用时，首先会将数据从用户缓存区复制到内核中去，从此之后，可能发生的情况就与连接的状态有关了，
TCP可能发送全部、部分或者不发数据。总的来说，除非TCP缓存区满了，否则写操作是不会被阻塞的，也就是说，写操作基本总是能立即返回的，
但他们返回时并不能保证对所写的数据进行了哪些处理。
写操作只返回写调用时发生的明显错误：
1. 套接字描述符无效
2. 使用send及其兄弟函数时，文件描述符指向不是套接字
3. 调用中指定的套接字不存在或未连接
4. 缓冲区地址参数指向无效地址
5. EPIPE错误(SIGPIPE信号)

1. TCP倾向于以MSS尺寸的块来发送数据。
2. 同时不能超出其对等实例缓冲区的范围，这是由TCP的发送窗口控制的。
3. 拥塞控制：防止路由器缓冲区空间被耗尽，造成数据包的丢失。
防止拥塞  慢启动 -> 拥塞避免
1. 拥塞窗口：TCP在任意时刻能够发送的最大数据量是发送和拥塞窗口中的最小值。
2. 慢启动  ："慢慢地"将向网络发送数据的速率增加到一个门限值。 慢启动门限。
3. 拥塞避免：

Nagle算法：Nagle算法实际上是SWS(silly Window Syndrome病态窗口综合征)避免算法集的一半。
    防止TCP用一系列的小段来充斥网络。
    TCP会将数量较少的数据保存起来，直到它收到对前一个小段的ACK为止，然后，将所有数据一次性发送出去。
    如果有未经确认的数据存在，就不要发送小段。
如果不允许使用Nagle算法的话，会对应用程序的有效性产生很大影响。
条件：如果应用程序用很小的块结构来写数据，Nagle算法的效果会很明显。

SWS避免算法： 发送端和接收端的SWS算法。
除非缓冲区空间有了"相当大的增加"，否则就就不发布窗口更新报文。
相当大的增加:大于窗口最大长度一半的增长，或者一个全尺段的增长。
}

BSD(TCP){
只要调用TCP输出例程，就会根据发送缓冲区、发送窗口长度、拥塞窗口长度和MSS中的最小值计算出可以发送的数据量。
只要下列某一项符合，数据就会被传送出来：
1. 可以发送一个完整MSS尺寸的段，
2. 连接空闲，并且可以清空发送缓冲区
3. Nagle算法被禁止，并且可以情况发送缓冲区
4. 有紧急数据需要发送
5. 有一小段"暂时"无法发送的数据：
    TCP有一个无法发送的小段时，会启动一个定时器，定时器的时长与发送了数据之后重传之前等待ACK的时长相同，
(需要满足5~60秒的时间限制)，也就是说，要将这个定时器设置为RTO。如果这个被称为持续定时器的定时器超时了，
TCP传输的段只需要满足发送和拥塞窗口的限制。即使对等实体广播了一个0字节的窗口，TCP仍然会试着发送1字节。
这是为了防止丢失的窗口更新信息造成死锁。
6. 对对等实体的接收窗口至少是半开的；
7. 需要重传一个段
8. 需要为来自对等实体的数据回送一个ACK
9. 需要发布一个窗口更新
}

怎样才能知道对等实体已经完成了数据传输阶段，准备拆除连接，以及如何将同样的信息传递给对等实体。
TTY连接，写操作上发生的所有错误都是从write调用自身返回的，而对TCP来说，错误很可能使用过读操作返回的。
book(理解TCP的有序释放操作){
数字   POSIX    Winsock      动作
0     SHUT_RD   SD_RECEIVE   关闭连接的接收端    当前缓冲区内数据被丢失，再接收的数据丢弃，回应ACK报文。再read，返回EOF
1     SHUT_WR   SD_SEND      关闭连接的发送端    向对等实体发送一个FIN，通知没有其他数据。              再write，返回错误
2     SHUT_RDWR SD_BOTH      两端都关闭          等同于调用shutdown(s,0)和shutdown(s,1)
Winsock中，如果不先how=2调用shutdown，closesocket就无法正常工作。

    shutdown调用 ：shutdown（int s, inthow）其中how0，1，2分别表示关闭接受，发送，两端。关闭套接字和shutdown之间是有很大的区别的，
即使将how值设为2来使用，实际上也没有"关闭"套接字，也就是说，并没有释放套接字及其资源。同时，调用shutdown时，会影响到所有打开了
那个套接字的进程。
   调用close或closesocket，套接字的其他持有者仍能像什么事情都没有发生一样使用它。
   
   shutdown: FIN报文，ACK报文，发送队列和接收队列，
   close   : 引用计数，然后才是发送队列和接收队列，
安全点请先shutdown，再close。
}

book(考虑用inetd来装载应用程序){
对TCP服务器来说，inetd负责监听应用程序知名端口上的连接请求，接受连接，将连接映射到stdin、stdout和stderr上去，并启动适当的服务器。
服务器运行时，从stdin读取输入，并将输出写入stdout或stderr.也就是说，通过文件描述符0,1,2就和对等实例连接起来了。

使用Inetd可以免除自己管理TCP连接或UDP。
rlnum stream tcp nowait jcs /usr/home/jcs/rlnumd rlnumd
1. 服务的名字就是/etc/services所列的名字。这是客户端使用这台服务器时所连接的知名端口的'名字'，服务的名字为rlnum
2. 服务器使用的套接字类型。对TCP服务器来说就是流stream,对UDP服务器来说是dgram。
3. 服务器使用的协议。可以是tcp也可以是udp
4. 等待/不等待标记。通常会等UDP服务器，而基本上都不会等待TCP服务器。
   指定不等待标记时，inetd都不会对套接字做其他操作。服务器终止时，它会恢复对(基于流的服务器上)连接或(基于数据包服务器上)数据包到达的监听。
   如果基于流的服务器指定等待标记，inetd不会为连接调用调用accept,而是会将监听套接字传递给服务器，服务器在终止前至少要接受一个连接。
   为TCP应用程序指定等待标识是一种有用但很少被理解的选择。
        做为不可靠网络守护进程的重启设备使用。只要守护进程正常运行，就会接受来自客户端的连接，但是如果守护进程由于某些原因崩溃了，inetd在收到
   一条连接请求时就会将其重启。
        作为确保一次只有一台客户端可以使用服务器的手段使用。
5. 运行服务器时使用的用户名
6. 服务器可执行文件的全路径名
7. 最多可以向服务器传递5个变元(从argv[0]开始)

    在UDP服务器的知名端口上有数据包可读时，inetd会指挥操作系统来通知它。通知抵达时，inetd套接字映射到stdin,stdout和stderr上，
并启动UDP服务器。与TCP服务器常用的不等待模式不同，在启动的服务器终止之前，inetd不会在知名端口上采取任何行动。
udpecho dgram udp wait jcs /usr/home/jcs/udpechod udpechod
udpecho
udpecho1

tcpmux/+rlnumd stream tcp nowait jcs /usr/home/jcs/rlnumd rlnumd  # inetd支持tcpmux功能
telnet localhost tcpmux #启动rlnumd
>rlnumd

}

tcpmux(考虑用tcpmux为服务器分配知名端口){
IANA(Internet Assigned Numbers Authority) -> 官方的知名端口，注册端口号，动态或私有端口号
官方的知名端口 0-1023
注册端口号     1024-49151
动态或私有端口号 49151-65535
tcpmux(TCP Port Service MultipleXor)
}

book(不要用TIME-WAIT暗杀来关闭一个连接){
TIME-WAIT在TCP中完成了哪些功能，以及为什么不要试图挫败？ 主动调用shutdown的一端会陷入 TIME-WAIT 状态。
TIME-WAIT状态是在连接撤除阶段开始起作用的。              被动调用shutdown的一端不会陷入 TIME-WAIT 状态。
   主机1          主机2
应用程序关闭        |
     |             FIN
   ACK              |
     |         应用程序关闭
   FIN              |
     |              ACK
     _________________关闭连接
     |              |
     |              |   TIME-WAIT (2MSL) Maximum Segment Lifttime 最大分段寿命
     _________________  2MSL：分段被丢弃之前在网络中可以存活的最大寿命，
     |                  TTL ：在官方声明中，TTL字段的单位是秒。
  关闭连接 

[TIME-WAIT 的影响]
1) 通常，只有一端 -- 主动关闭的那一端会进入TIME-WAIT状态；
   还存在同时关闭的情况，那么，双方都认为是主动关闭情况，都会进入TIME-WAIT状态。
2) RFC 793将MSL定义为2分钟。根据这个定义，连接会在TIME-WAIT状态停留4分钟。
   BSD派生系统就将30秒作为MSL，这样TIME-WAIT状态就会持续一分钟。从0.5~2分钟之间的其他值也经常被用到。
3) 如果连接处于TIME-WAIT状态时有分组达到，就重启2MSL的定时器。

[TIME-WAIT 的原因]
1) 维护连接状态，以防主动关闭连接的那端发送的最后一条ACK丢失后造成另一端重新发送FIN信号；
2) 为耗尽网络中所有此链接的"走失段"提供时间。

[TIME-WAIT 的不存在的影响]
1.1) 被动结束端重传FIN，TCP就已经没有这条连接的记录，所以他会用RST来响应。
     被动结束端就会产生一个错误状态，而不会有序地终止。
1.2) 在WAN连接中，存在很多乱序，重传和延迟的情况。如果延迟和重传的报文在TCP关闭之后达到。TCP协议栈将发送RST报文。
     如果在这两台主机间用同样的端口号建立了一条新连接，这条走失的段看起来就像属于哪条新连接。
     同时RST正好落在接收窗口，就会造成严重破坏。
     
[TIME-WAIT 暗杀: TIME-WAIT状态可能被提前终止]
1) 当一条连接处于TIME-WAIT状态并收到一个RST时，应该立即将连接关闭。 RFC 1337对这种可能进行进行描述。
   对TCP进行修改，使其忽略TIME-WAIT状态下的RST，就可以很容易地防止这种可能性发生。BSD协议栈就是这样做的。
2) 程序员可以用套接字选项SO_LINGER迫使连接立即关闭。
   有时会推荐用这种可以的方式是服务器跳出TIME-WAIT状态，这样就可以在崩溃或终止之后重启服务器。
}

SO_LINGER(){
tcp_close() -> tcp_send_fin() -> __tcp_push_pending_frames() -> tcp_write_xmit()

    通常，应用程序关闭一条连接时，即时发送缓冲区仍有数据要发送，close或closesocket调用也会立即返回。当然，TCP
还是会尝试着发送未发送出去的数据，但应用程序并不知道是否发送成功了。为防止这个问题的发送，我们设置了套接字选项
SO_LINGER。填写Linger结构，并用SO_LINGER调用setsockopt来设置这个选项。

linger # 只能保证数据传递给了对等实体的TCP。不能保证数据被对等实体应用程序读走了。
    l_onoff  # on/off选项
    l_linger # 逗留时间
[l_linger!=0 l_onoff=on]
# 非阻塞的情况
如果逗留定期器到期时，仍然有未发送的数据，close或closesocket就返回EWOULDBLOCK，所有未发送数据都能丢失。
如果数据都发送出去了，这两个调用就都返回0。
# 阻塞的情况
此时函数close()将被阻塞（假定为阻塞模式）直到：
1) 待发送的数据全部得到了对端确认，返回值为0；
2) 发生信号中断或异常（比如意外收到对端发送过来的数据）或超时，返回值为0；

[l_linger=0 l_onoff=on]  很危险
就将连接丢弃。也就说，向对等实体发送一个RST，不经过TIME-WAIT状态就立即关闭连接。
}

TCP_DEFER_ACCEPT(){
    TCP半连接攻击。这种攻击的原理很容易理解，既然服务器要在收到客户端的请求（即SYN数据包到达）后创建相关
结构体等而需要消耗系统资源（比如内存，即便是像Linux这种做了优化处理，一次消耗的资源比较少），因此，如果
客户端持续发送大量的SYN包，那么就会不断的消耗服务器端的可用资源，如果针对服务器发回的SYN+ACK包，客户端
也不做出ACK回复，从而使得服务器反复发送SYN+ACK包导致情况进一步恶化，每个请求连接都持续如此直到连接的最终
超时，而在这个持续的过程中，可能有些正常的客户端请求，服务器端因为系统资源不足而无法创建连接、提供服务。
    Syn_cookies是针对TCP半连接攻击的重要防范方法之一，原理也很简单，既然TCP半连接攻击的基本原理是服务器端
会在收到客户端的SYN包时消耗资源，那么最简单的防范也就是服务器端在收到客户端的SYN包时尽量不做资源分配，
把这个动作延后处理。

    另外，值得说明一点的是，并非开启Linux系统的Syn_cookies选项（即：echo 1 > /proc/sys/net/ipv4/tcp_syncookies）
就会立即让Linux TCP协议栈对每一个客户端请求都走发送Syn Cookies的流程，而只有在系统判断当前请求达到一定数量
且满足相关条件时才会这么做。

TCP_DEFER_ACCEPT：它将服务器端连接套接口转变成ESTABLISHED状态的时机后移。具体来讲，就是只有当服务器端
                  收到客户端发送的实际请求数据后，才建立其对应的连接套接口。
    如果同时开启Syn_cookies，那么对于需要走发送Syn Cookies流程的客户端请求就按照前面介绍的Syn_cookies图示，
即此时Syn_cookies起主导作用，但这并不是说Syn_cookies与选项TCP_DEFER_ACCEPT不能共用，前面说过，即便是启动
Syn_cookies，也并不是所有的客户端请求都会走发送Syn Cookies的流程，所以对于那些不走Syn Cookies流程并且开启
选项TCP_DEFER_ACCEPT的监听套接口，

    TCP全连接攻击：Syn_cookies使得服务器对系统资源的分配做了一次延后处理，也就是拖延了Linux TCP协议栈（内核态）
对资源进行分配的时机，从而在一定程度上防御TCP半连接攻击；但如果客户端发起的是TCP全连接攻击，即客户端发出正常
的TCP三次握手流程把连接建立起来（此种情况，Syn_cookies当然是通过的），但不发送任何实际请求数据（因为一旦发送
实际的请求数据，服务器端就能进行下一步处理，可能提前判断出请求有错或处理完成而结束，从而达不到让服务器长时间
等待消耗的目的），达到消耗服务器应用层（用户态）资源的目的。
}

TCP_CORK(){
    选项TCP_NODELAY是禁用Nagle算法，即数据包立即发送出去，而选项TCP_CORK与此相反，可以认为它是
Nagle算法的进一步增强，即阻塞数据包发送，具体点说就是：TCP_CORK选项的功能类似于在发送数据管道
出口处插入一个"塞子"，使得发送数据全部被阻塞，直到取消TCP_CORK选项（即拔去塞子）或被阻塞数据
长度已超过MSS才将其发送出去。
}
book(服务器应设置SO_REUSEADDR选项){
     TCP服务器端需要设置SO_REUSEADDR选项，而UDP服务器端不需要设置SO_REUSEADDR选项。
     
    当我们服务器崩溃之后，试图重启时，会收到错误的提示“Address already in use“，过了几分钟后才能重启服务器。

    因为这时候主动停止的那一端还处于TIME-WAIT状态，并在此状态停留 了2MSL，通过设置套接字选项SO_REUSEADDR，
指示TCP允许我们绑定到一个已经在使用的端口上去。
}
book(高并发TCP服务器中进行主动关闭的一方最好是客户端){
    因为对于高并发服务器来说文件描述符资源是很重要的资源，如果对于每一个连接都要经历TIME_WAIT这个2MSL的时长，
势必造成资源不能立马复用的浪费。虽然对于客户端来说TIME_WAIT状态会占用端口和句柄资源，但是客户端一般很少有并发
资源限制，所以客户端执行主动关闭是比较合适的。
}
link(TCP/IP协议栈中，为什么选择IP层负责分片？){
如果要在最低层的数据链路层做分片，你必须要去对不同的物理网络的驱动程序做更改； 
如果要在上层的传输层或者应用层做分片，既然数据都要通过网络层实际上就是各协议对分片功能的重复造轮子，我们有必要付出这种成本去实现分片吗？
我想IP层就是我们在软件设计里常用的适配层，着这里做分片是成本最低的选择。
}
link(TCP相关时延){
1. TCP连接建立握手
2. TCP的延迟确认机制 通常是100-200毫秒
3. TCP慢启动（拥塞控制） - 新连接的传输速度会比已经交换过一定量数据的连接慢一些。
4. Nagle算法与TCP_NODELAY - 如小的HTTP报文可能无法填满一个分组，所以要缓存等待起来，要么就等待确认分组的抵达（确认分组的时延大概在100-200毫秒）。
   HTTP应用程序常常会在自己的协议栈中设置参数TCP_NODELAY，禁用Nagle算法来提高性能。
5. TIME_WAIT累积与端口耗尽
}
link(HTTP请求过程中会有哪些网络时延？){
1. 域名解析：
2. 接下来，客户端会向服务器发送一条TCP连接请求，并等待服务器回送一条响应。
3. 一旦连接建立起来，客户端和服务器端就会通过这个建立的TCP管道来进行请求的收发了，
  这些TCP的网络时延的大小取决于硬件速度、网络和服务器的负载，请求和响应报文的尺寸，
  以及客户端和服务器之间的距离。
}
link(构建高性能服务的考量){
1. 2/5/10法则：用户响应在2秒之内是很好的用户体验；用户响应在2-5秒之间是一般的用户体验，用户可以接受；
   但是用户响应在5-10秒之间是很糟糕的用户体验，已经接近了用户可接受的极限。
   
1. 数据在网络上传输的时间；
2. 后台服务器处理请求并生成回应的时间；
3. 客户端处理回复并进行UI呈现的时间；

响应时间 = 发送时间 + 传播时间 + 处理时间。

[发送时间]
# 发送时间 网络方面：发送时间 = 数据量/带宽
1. 将要发送的数据写入进程的数据缓冲区；
2. 调用系统API，这里涉及到用户态到内核态的转化，将数据存入系统内核缓冲区；
3. 数据从内核缓冲区进入网卡；
4. 数据从网卡传输到网络线路；
5. 数据在线路中转换成相应的信号通过介质进行传输；

[传播时间]
传播时间 = 传输距离/传输速度。

[响应时间]
响应时间 = 数据量/带宽 + 传输距离/传输速度 + 处理时间
}

link(高性能服务器开发的关注点){
1、如果基于通用组件编程，关注点多是在组件如何封装套接字编程细节。为了使应用程序不感知套接字层，
   这些组件往往是通过各种回调机制来向应用层代码提供网络服务，通常，出于为应用层提供更高的开发效率，
   组件都大量使用了线程（Nginx等是个例外），当然，使用了线程后往往可以降低代码复杂度。
   但多线程引入的并发解决机制还是需要重点关注的，特别是锁的使用。另外，使用多线程意味着把应用层的
   代码复杂度扔给了操作系统，大吞吐量时，需要关注多线程给操作系统内核带来的性能损耗。 
基于通用组件编程，为了程序的高性能运行，需要清楚的了解组件的以下特性：
1. 怎么使用IO多路复用或者异步IO的？
2. 怎么实现并发性的？
3. 怎么组织线程模型的？
4. 怎么处理高吞吐量引发的异常情况的？

2、通用组件只是在封装套接字，操作系统是通过提供套接字来为进程提供网络通讯能力的。
学习套接字编程，关注点主要在：
1. 套接字的编程方法有哪些？
2. 阻塞套接字的各方法是如何阻塞住当前代码段的？
3. 非阻塞套接字上的方法如何不阻塞当前代码段的？
4. IO多路复用机制是怎样与套接字结合的？
5. 异步IO是如何实现的？
6. 网络协议的各种异常情况、操作系统的各种异常情况是怎么通过套接字传递给应用性程序的？

3、网络的复杂性会影响到服务器的吞吐量，而且，高吞吐量场景下，多种临界条件会导致应用程序的不正常，
   特别是组件中有bug或考虑不周或没有配置正确时。了解网络分组可以定位出这些问题，可以正确的配置系统、
   组件，可以正确的理解系统的瓶颈。 
这里的关注点主要在：
1. TCP、UDP、IP协议的特点？
2. linux等操作系统如何处理这些协议的？
3. 使用tcpdump等抓包工具分析各网络分组。

}
link(你打算怎样实现客户端的网络层？){
问：你打算怎样实现客户端的网络层？
答：对于TCP协议来说无非就是connect，send，recv呗。

问：那你是否考虑到这种情况，你同时或者先后发过去两个网络请求，你怎么确定你收到回复是哪个请求的？
（其实问到这时有些同事就开始不理解了，我会给他们解释网络传输和服务器处理不是串行的，往往会出现你后发的请求却先收到回复，客户端 多线程情况下更为常见。当然也有有办法的。）
答：那我对每一个请求加一个唯一标识，这样我就可以分辨出来了。

问：你有没有考虑过由于connect，send，recv...这些系统API都是阻塞的，如果没有限制条件，会让你的一个请求卡住很长时间或者永远卡住？
问：你有没有考虑过短连接请求，长连接请求，服务端推送消息如何实现？
问：你有没有考虑过各种网络错误和异常的监控和处理，比如TCP长连接网络断开后的自动重连？
问：你有没有考虑过如果你把网络层或者网络数据层和前台业务和界面混杂在一起后的代码混乱复杂度？
问：你对TCP了解多少，仅仅是会用网络编程的API还是知道TCP还拥有一些诸如TIME_WAIT、TCP_NODELAY...的状态或特性，你知道经常说的粘包是怎么回事吗？
}
book(如何使connect调用超时){
    通常在套接字阻塞的情况下，在收到对客户端SYN的ACK之前，connect是不会返回的，如果网络阻塞，或者要连接的主机还没有启动，
所需要时间可能更长，因此允许放弃connect通常是一项很有用的功能，当然TCP最终会放弃connect调用，但是默认时间（75秒）可能比
我们希望等待的时间要长。

    有两种方法，其一在connect前使用alarm(inttime)告警，表示希望等待的时间不超过time秒。
    其二，在connect之前使用select，在select中设置时间超时。
}

book(避免数据复制){
其一，如果知道要在读取到缓冲区的数据的前面加上一个首部，在读取时就应该为其留有空间。
其二，将报文分组定义为一个结构，这个结构将数据缓冲区作为它的一个元素，然后只要将数据读入适当的结构字段中去就可以了。
其三，使用合并写操作。
使用共享内存几乎可以避免所有的数据复制，包括进程间的。
}

book(使用前将结构sockaddr_in清零){
    尽管通常我们只是用sockaddr_in结构的三个字段，sin_family,sin_port和sin_addr，但在大多数实现中它还包含其他部分，
因此必须在使用钱，将整个地址结构清零就成了一种惯用的做法。
}

book(不要忘记字节的性别){
为了避免互操作性问题，所有整数协议数据都是以big endian形式的网络字节序传输的。
gethostbyname和getservbyname的解析函数都是以网络字节序返回值的。
}

book(理解已连接的UDP套接字){
对TCP来说，connect的作用之一就是将远程实体的地址和端口绑定到本地套接字上去。
           bind的功能是将本地地址和端口绑定到套接字上去。
对UDP来说，connect的作用之一就是将远程主机的地址和端口绑定到本地套接字上去。
1) 不再使用sendto，而是使用send或write来发送数据。
    仍然可以对已连接的UDP套接字使用sendto，但必须将指向对等实体地址的指针设置为NULL，并将其长度设置为零，
    当然，还可以使用sendmsg，仍然要先将msghdr结构的msg_name字段设置为NULL，并将其长度设置为零。
2) 使用connect确实对性能有很大的提高。
3) UDP数据包的发送者连接到其对等实体的主要原因还是为了接收异步错误通知。  
   ICMP不可达报文。ICMP报文中包含了UDP发送报文的报文头部信息。
   EISCONN      # 在connect之后，sendto或sendmsg发送数据仍然指定了IP地址造成的
   ECONNREFUSED # 在connect连接的主机端口未打开的情况下，recvfrom调用触发的错误
}
book(理解缓冲区长度带来的影响){
带宽时延积(bandwith-delay product):BWD
BWD = 带宽*RTT = 比特/秒 * 秒 = 比特
}

book(ping tcpdump traceroute ttcp lsof netstat trace strace){
netlog 
nettimer 
Ethereal 
iperf
}
book(TCP是个可靠的，但不是完全可靠的){
TCP在哪种情况下会出错？这里说的"出错"指的是收到的数据与发送的数据不一致，而不是数据不可达。

故障模式
(1) 永久或临时的网络中断；
    除非中间路由器发送一条ICMP报文，说明目的网络或主机不可达，否则应用程序及其TCP/IP栈都无法立即
获知中断的发生。在这种情况下，发送端最终会超时，并重新发送所有未被确认的段。在发送端TCP放弃发送、
丢弃连接并报告错误之前会一直持续这种操作。在传统BSD栈中，发送端TCP会在重传12次（大约9分钟）之后
放弃。如果读操作被挂起，会返回一条错误状况，并将errno置为ETIMEDOUT。如果没有挂起的读操作，接下来
的写操作就会失败，根据信号是忽略还是捕获，写操作失败时会携带一个SIGPIPE信号，或EPIPE错误。
    如果某个中间路由器无法转发包含段的IP数据报，它会向源端主机发送一个ICMP报文，说明目的网络或
主机不可达。在这种情况下，有些实现会返回ENETUNREACH或EHOSTUNREACH作为错误原因。
    ETIMEDOUT错误
    EHOSTUNREACH或ENETUNREACH错误
(2) 对等的应用程序崩溃；
    首先要意识到从应用程序的角度来看，对等实体崩溃与对等实体调用close（或者是Windows应用程序中的
closesocket）及exit是无法区分的。在这两种情况下，对等实体的TCP都会向我们的TCP发送一个FIN。FIN作为
EOF使用，表示发送它的那一端已经没有数据发送了。这并不（一定）表示发送FIN的这一端已经退出了，甚至
无法说明它不愿意接收更多数据。
    1. 客户端数据已发送，阻塞在接收时，服务器正好崩溃； "server terminated" 内核：接收到FIN 用户态：EOF
    2. 客户端数据已接受，阻塞在其他IO，服务器正好崩溃；再次读数据； "Connection reset by peer" 接收到RST 用户态：EOFECONNRESET
    3. 客户端数据已接受，阻塞在其他IO，服务器正好崩溃；再次写数据； 内核：接收到RST 用户态：SIGPIPE
(3) 运行对等应用程序的主机崩溃。
    1. 内核态接收不到FIN和RST报文，用户态只能接收到：ETIMEOUT；
    2. 服务器端机器重启： 读[内核RST 用户态ECONNRESET] 写[内核RST 用户态SIGPIPE]
    
[网线断开]
1. 如果网线断开的时间短暂，在SO_KEEPALIVE设定的探测时间间隔内，并且两端在此期间没有任何针对此长连接的网络操作。
   当连上网线后此TCP连接可以自动恢复，继续进行正常的网络操作。
2. 如果网线断开的时间很长，超出了SO_KEEPALIVE设定的探测时间间隔，或者两端期间在此有了任何针对此长连接的网络操作。
   当连上网线时就会出现ETIMEDOUT或者ECONNRESET的错误。你必须重新建立一个新的长连接进行网络操作。
}

out(协议设计是网络编程的核心){
    对于专用的业务系统，协议设计是核心任务，决定了系统的开发难度与可靠性，但是这个领域还没
有形成大家公认的设计流程。
    比新建连接难的是关闭连接。在传统的网络服务中（特别是短连接服务），不少是服务端主动关闭
连接，比如daytime、HTTP/1.0。也有少部分是客户端主动关闭连接，通常是些长连接服务，比如  echo、
chargen等。我们自己的业务系统该如何设计连接关闭协议呢？
    服务端主动关闭连接的缺点之一是会多占用服务器资源。服务端主动关闭连接之后会进入
TIME_WAIT状态，在一段时间之内hold住一些内核资源。如果并发访问量很高，这会影响服务端的处
理能力。这似乎暗示我们应该把协议设计为客户端主动关闭，让TIME_WAIT状态分散到多台客户机器
上，化整为零。 
    消息格式很好办，XML、JSON、Protobuf都是很好
的选择；难的是消息内容。一个消息应该包含哪些内容？多个程序相互通信如何避免race condition（见
《分布式系统的工程化开发方法》p.16的例子）？系统的全局状态该如何跃迁？

}

ibm(持久的传输控制协议（Transmission Control Protocol，TCP）连接){
    如果您打算为每个请求或者事务发起不同的 TCP 连接，那么上述的技术很明显会失效。您应该重用现有的
连接，当然这并不是唯一的原因。在建立和拆除连接的过程中，TCP 握手可能会带来巨大的开销，当然最好能够
避免这个开销。
    如果不能正确地关闭 TCP 连接，那么可能很快会给您的 UNIX 系统带来各种各样的麻烦。另一个因素是新
的连接中的协议开销。您希望确保网络尽可能用于实际数据，而不是交换 Header 以及其他控制信息。
}
ibm(非阻塞的 I/O、select 和 poll){
1. 阻塞和非阻塞套接字大致上对应于同步和异步处理，但并不是在网络级别，而是在操作系统级别。

}
listen(){
在进程/线程(监听者)监听的过程中，它阻塞在select()或poll()上。
直到有数据(SYN信息)写入到它所监听的sockfd中(即recv buffer)，监听者被唤醒并将SYN数据拷贝到用户空间中自己管理的app buffer中进行一番处理，并发送SYN+ACK
这个数据同样需要从app buffer中拷入send buffer(使用send()函数)中，再拷入网卡传送出去。
这时会在连接未完成队列中为这个连接创建一个新项目，并设置为SYN_RECV状态。
然后再次使用select()/poll()方式监控着套接字listenfd，直到再次有数据写入这个listenfd中监听者才被唤醒，
1. 如果这次写入的数据是ACK信息，则将数据拷入到app buffer中进行一番处理后，把连接未完成队列中对应的项目移入连接已完成队列，并设置为ESTABLISHED状态，
2. 如果这次接收的不是ACK，则肯定是SYN，也就是新的连接请求，于是和上面的处理过程一样，放入连接未完成队列。这就是监听者处理整个TCP连接的循环过程。
# listen()函数还维护了两个队列：连接未完成队列和连接已完成队列。

当未完成连接队列满了，监听者被阻塞不再接收新的连接请求，并通过select()/poll()等待两个队列触发可写事件。
当已完成连接队列满了，则监听者也不会接收新的连接请求，同时，正准备移入到已完成连接队列的动作被阻塞。
backlog的参数:表示已完成队列的最大长度
/proc/sys/net/ipv4/tcp_max_syn_backlog则用于设置未完成队列的最大长度。
/proc/sys/net/core/somaxconn则是硬限制已完成队列的最大长度，默认为128，如果backlog大于somaxconn，则backlog会被截断为等于该值。

注意，Listen状态下的套接字，netstat的Send-Q和ss命令的Send-Q列的值不一样，因为netstat根本就没写上已完成队列的最大长度。因此，判断队列中是否还有空闲位置接收新的tcp连接请求时，应该尽可能地使用ss命令而不是netstat。
netstat -tnl
ss      -tnl
}
flood(listen){
解决syn flood的方法有多种，例如，缩小listen()维护的两个队列的最大长度，减少重发syn+ack的次数，
增大重发的时间间隔，减少收到ack的等待超时时间，使用syncookie等，但直接修改tcp选项的任何一种
方法都不能很好兼顾性能和效率。
所以在连接到达监听者线程之前对数据包进行过滤是极其重要的手段。
}
tcp(高性能服务器：accept建立连接){
网络IO中应用服务器往往聚焦于以下几个由网络IO组成的功能中：
A）与客户端建立起TCP连接。
B）读取客户端的请求流。
C）向客户端发送响应流。
D）关闭TCP连接。
E）向其他服务器发起TCP连接。

[SYN队列和ACCEPT队列]
    当服务器绑定、监听了某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。客户端使用connect向服务器发起TCP连接，
当客户端的SYN包到达了服务器后，内核会把这一信息放到SYN队列（即未完成握手队列）中，同时回一个SYN+ACK包给客户端。
一段时间后，在较中2步骤中客户端再次发来了针对服务器SYN包的ACK网络分组时，内核会把连接从SYN队列中取出，
再把这个连接放到ACCEPT队列（即已完成握手队列）中。而服务器在第3步调用accept时，其实就是直接从ACCEPT队列中取出
已经建立成功的连接套接字而已。
1. 若SYN队列满，则会直接丢弃请求，即新的SYN网络分组会被丢弃；
2. 如果ACCEPT队列满，则不会导致放弃连接，也不会把连接从SYN列队中移出，这会加剧SYN队列的增长。
}
tcp(高性能网络编程:TCP消息的发送){
MTU、MSS、tcp_write_queue发送队列、阻塞与非阻塞套接字、拥塞窗口、滑动窗口、Nagle算法。

1、MSS与TCP的分片
---------------------------------------
    IP层同时希望这个分片对于传输层来说是透明的，接收方的IP层会根据收到的多个IP包头部，将发送方IP层
分片出的IP包重组为一个消息。这种IP层的分片效率是很差的，因为必须所有分片都到达才能重组成一个包，其中
任何一个分片丢失了，都必须重发所有分片。所以，TCP层会试图避免IP层执行数据报分片。
为了避免IP层的分片，TCP协议定义了一个新的概念：最大报文段长度MSS。

    当应用层调用TCP层提供的发送方法时，内核的TCP模块在tcp_sendmsg方法里，会按照对方告知的MSS来分片，把
消息流分为多个网络分组（如图1中的3个网络分组），再调用IP层的方法发送数据。
<如何避免分片>
    通过IP头部的DF标志位，这个标志位是告诉IP报文所途经的所有IP层代码：不要对这个报文分片。如果一个IP报文
太大必须要分片，则直接返回一个ICMP错误，说明必须要分片了，且待分片路由器网络接受的MTU值。这样，连接上的
发送方主机就可以重新确定MSS。

2、发送方法返回成功后，数据一定发送到了TCP的另一端吗？
---------------------------------------
（1）应用程序试图调用send方法来发送一段较长的数据。
（2）内核主要通过tcp_sendmsg方法来完成。
（3）（4）按照MSS来划分，放到tcp_write_queue发送队列中
（5）内核中为这个TCP连接分配的内核缓存是有限的(/proc/sys/net/core/wmem_default)sk_stream_wait_memory
（6）在假定使用了阻塞套接字，且等待了足够久的时间，收到了对方的ACK，滑动窗口释放出了缓存。
（7）将剩下的用户态数据都组成MSS报文拷贝到内核态的sk_buff中。
（8）最后，调用tcp_push等方法，它最终会调用IP层的方法来发送tcp_write_queue队列中的报文。
    注意，IP层返回时，并不一定是把报文发送了出去。
（9）（10）发送方法返回。
    无论是使用阻塞还是非阻塞套接字，发送方法成功返回时（无论全部成功或者部分成功），既不代表TCP连接的另一端
主机接收到了消息，也不代表本机把消息发送到了网络上，只是说明，内核将会试图保证把消息送达对方。

3、Nagle算法、滑动窗口、拥塞窗口对发送方法的影响
---------------------------------------
tcp_push方法做了些什么呢？
    tcp_push在发送数据时当然需要与发送窗口打交道。发送窗口是一个时刻变化的值，随着ACK的到达会变大，随着发出新
的数据包会变小。当然，最大也只能到三次握手时对方通告的窗口大小。

慢启动和拥塞窗口？
1. 慢启动算法说白了，就是对方通告的窗口大小只表示对方接收TCP分组的能力，不表示中间网络能够处理分组的能力。
2. 发送方请悠着点发，确保网络非常通畅了后，再按照对方通告窗口来敞开了发。
tcp_cwnd_test方法检查飞行的报文数是否小于拥塞窗口个数
tcp_window_allows方法获取拥塞窗口与滑动窗口的最小长度，检查待发送的数据是否超出

是否符合NAGLE算法？
Nagle算法要求一个TCP连接上最多只能有一个发送出去还没被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。
内核中是通过 tcp_nagle_test方法实现该算法的，tcp_nagle_check，tcp_minshall_check
}
tcp(高性能网络编程:TCP消息的接收){
暂时忽略ACK报文的回复和接收窗口的滑动。
---------------------------------------
1、应用程序调用read、recv等方法时，socket套接字可以设置为阻塞或者非阻塞，这两种方式是如何工作的？
2、若socket为默认的阻塞套接字，此时recv方法传入的len参数，是表示必须超时（SO_RCVTIMEO）或者接收到len长度的消息，recv方法才会返回吗？而且，socket上可以设置一个属性叫做SO_RCVLOWAT，它会与len产生什么样的交集，又是决定recv等接收方法什么时候返回？
3、应用程序开始收取TCP消息，与程序所在的机器网卡上接收到网络里发来的TCP消息，这是两个独立的流程。它们之间是如何互相影响的？例如，应用程序正在收取消息时，内核通过网卡又在这条TCP连接上收到消息时，究竟是如何处理的？若应用程序没有调用read或者recv时，内核收到TCP连接上的消息后又是怎样处理的？
4、recv这样的接收方法还可以传入各种flags，例如MSG_WAITALL、MSG_PEEK、MSG_TRUNK等等。它们是如何工作的？
5、1个socket套接字可能被多个进程在使用，出现并发访问时，内核是怎么处理这种状况的？
6、linux的sysctl系统参数中，有类似tcp_low_latency这样的开关，默认为0或者配置为1时是如何影响TCP消息处理流程的？

<tcp_low_latency>
系统参数tcp_low_latency设置为0，即从操作系统的总体效率出发，使用prequeue队列提升吞吐量。

<receive队列>
注意：receive队列是允许用户进程直接读取的，它是将已经接收到的TCP报文，去除了TCP头部、
    排好序放入的、用户进程可以直接按序读取的队列。
每次向receive队列插入报文时都会检查out_of_order队列。

<out_of_order队列>
从这个队列名称就可以看出来，所有乱序的报文都会暂时放在这。

<backlog队列>
backlog队列是进程正在拷贝数据时，网卡收到的报文会进这个队列。

<prequeue队列>
用户进程调用recv方法时，连接上没有任何接收并缓存到内核的报文，而socket是阻塞的，所以进程睡眠了。
然后网卡中收到了TCP连接上的报文，此时prequeue队列开始产生作用。
}

tcp(高性能网络编程:TCP连接的关闭){
1、当socket被多进程或者多线程共享时，关闭连接时有何区别？
2、关连接时，若连接上有来自对端的还未处理的消息，会怎么处理？
3、关连接时，若连接上有本进程待发送却未来得及发送出的消息，又会怎么处理？
4、so_linger这个功能的用处在哪？
5、对于监听socket执行关闭，和对处于ESTABLISH这种通讯的socket执行关闭，有何区别？

listen:1）关闭监听句柄
    如何关闭半连接？这时当然不能发FIN包，即正常的四次握手关闭连接，而是会发送RST复位标志去关闭请求。处理完所有
半打开的连接close的任务就基本完成了。
对于监听句柄，如果参数为关闭写，显然没有任何意义。但关闭读从某方面来说是有意义的，例如不再接受新的连接。

1. 若shutdown的是半打开的连接，则发出RST来关闭连接。
2. 若shutdown的是正常连接，那么关闭读其实与对端是没有关系的。只要本机把接收掉的消息丢掉，其实就等价于关闭读了，
   并不一定非要对端关闭写的。实际上，shutdown正是这么干的。若参数中的标志位含有关闭读，只是标识下，当我们调用
   read等方法时这个标识就起作用了，会使进程读不到任何数据。
3. 若参数中有标志位为关闭写，那么下面做的事与close是一致的：发出FIN包，告诉对方，本机不会再发消息了。

如果是客户端请求断开，那么服务端就是被动断开端，可能会保留大量的CLOSE-WAIT状态的连接，
如果是服务端主动请求断开，则可能会保留大量的TIME_WAIT状态的连接。
}

tcp(高性能网络编程:tcp连接的内存使用){
net.ipv4.tcp_rmem = 8192 87380 16777216  
net.ipv4.tcp_wmem = 8192 65536 16777216  
net.ipv4.tcp_mem = 8388608 12582912 16777216  
net.core.rmem_default = 262144  
net.core.wmem_default = 262144  
net.core.rmem_max = 16777216  
net.core.wmem_max = 16777216  

tcp_rmem[3]数组表示任何一个TCP连接上的读缓存上限，其中tcp_rmem[0]表示最小上限，tcp_rmem[1]表示初始上限

net.ipv4.tcp_moderate_rcvbuf = 1  
net.ipv4.tcp_adv_win_scale = 2  

一、缓存上限是什么？
---------------------------------------
（1）先从应用程序编程时可以设置的SO_SNDBUF、SO_RCVBUF说起。
1. SO_SNDBUF、SO_RCVBUF都是个体化的设置，即，只会影响到设置过的连接，而不会对其他连接生效。
2. SO_SNDBUF表示这个连接上的内核写缓存上限。实际上，进程设置的SO_SNDBUF也并不是真的上限，在内核中会把这个值翻一倍再作为写缓存上限使用，
3. SO_SNDBUF会受制于系统级的上下限，当它大于上面的系统配置wmem_max（net.core.wmem_max）时，将会被wmem_max替代（同样翻一倍）；
   而当SO_SNDBUF特别小时，例如在2.6.18内核中设计的写缓存最小值为2K字节，此时也会被直接替代为2K。

4. SO_RCVBUF表示连接上的读缓存上限，与SO_SNDBUF类似，它也受制于rmem_max配置项，实际在内核中也是2倍大小作为读缓存的使用上限。
5. SO_RCVBUF设置时也有下限，同样在2.6.18内核中若这个值小于256字节就会被256所替代。

6. 只有当接收网络报文的速度大于应用程序读取报文的速度时，可能使读缓存达到了上限，这时这个缓存使用上限才会起作用。
   所起作用为：丢弃掉新收到的报文，防止这个TCP连接消耗太多的服务器资源。同样，
   当应用程序发送报文的速度大于接收对方确认ACK报文的速度时，写缓存可能达到上限，从而使send这样的方法失败，
   内核不为其分配内存。

二、缓存的大小与TCP的滑动窗口到底有什么关系？
---------------------------------------
（1）滑动窗口的大小与缓存大小肯定是有关的，但却不是一一对应的关系，更不会与缓存上限具有一一对应的关系。

读缓存的作用有2个：1、将无序的、落在接收滑动窗口内的TCP报文缓存起来；
                   2、当有序的、可以供应用程序读取的报文出现时，由于应用程序的读取是延时的，
所以会把待应用程序读取的报文也保存在读缓存中。所以，读缓存一分为二，一部分缓存无序报文，一部分缓存待延时读取的有序报文。

（2）最大读缓存到底应该设置到多少为合适呢？
若我们的带宽为2Gbps，时延为10ms，那么带宽时延积BDP则为2G/8*0.01=2.5MB，所以这样的网络中可以设最大接收窗口为2.5MB，
这样最大读缓存可以设为4/3*2.5MB=3.3MB。

三、linux的TCP缓存上限自动调整策略
---------------------------------------
linux为了实现这种场景，引入了自动调整内存分配的功能，由tcp_moderate_rcvbuf配置决定，如下：
net.ipv4.tcp_moderate_rcvbuf = 1
默认tcp_moderate_rcvbuf配置为1，表示打开了TCP内存自动调整功能。若配置为0，这个功能将不会生效（慎用）。

另外请注意：当我们在编程中对连接设置了SO_SNDBUF、SO_RCVBUF，将会使linux内核不再对这样的连接执行自动调整功能！

tcp_mem[3]数组就用来设定TCP内存的整体使用状况，所以它的值很大（它的单位也不是字节，而是页--4K或者8K等这样的单位！）。这3个值定义了TCP整体内存的无压力值、压力模式开启阀值、最大使用值。以这3个值为标记点则内存共有4种情况：

1、当TCP整体内存小于tcp_mem[0]时，表示系统内存总体无压力。若之前内存曾经超过了tcp_mem[1]使系统进入内存压力模式，
   那么此时也会把压力模式关闭。
   这种情况下，只要TCP连接使用的缓存没有达到上限（注意，虽然初始上限是tcp_rmem[1]，但这个值是可变的，下文会详述），
   那么新内存的分配一定是成功的。

2、当TCP内存在tcp_mem[0]与tcp_mem[1]之间时，系统可能处于内存压力模式，例如总内存刚从tcp_mem[1]之上下来；
   也可能是在非压力模式下，例如总内存刚从tcp_mem[0]以下上来。
   此时，无论是否在压力模式下，只要TCP连接所用缓存未超过tcp_rmem[0]或者tcp_wmem[0]，那么都一定都能成功分配新内存。
   否则，基本上就会面临分配失败的状况。（注意：还有一些例外场景允许分配内存成功，由于对于我们理解这几个配置项意义不大，
   故略过。）

3、当TCP内存在tcp_mem[1]与tcp_mem[2]之间时，系统一定处于系统压力模式下。其他行为与上同。

4、当TCP内存在tcp_mem[2]之上时，毫无疑问，系统一定在压力模式下，而且此时所有的新TCP缓存分配都会失败。


总结下，对这3个数组可以这么看：
---------------------------------------
1、只要系统TCP的总体内存超了 tcp_mem[2] ，新内存分配都会失败。
2、tcp_rmem[0]或者tcp_wmem[0]优先级也很高，只要条件1不超限，那么只要连接内存小于这两个值，就保证新内存分配一定成功。
3、只要总体内存不超过tcp_mem[0]，那么新内存在不超过连接缓存的上限时也能保证分配成功。
4、tcp_mem[1]与tcp_mem[0]构成了开启、关闭内存压力模式的开关。在压力模式下，连接缓存上限可能会减少。
   在非压力模式下，连接缓存上限可能会增加，最多增加到tcp_rmem[2]或者tcp_wmem[2]。
}

perf(也谈如何构建高性能服务端程序){
1. Cache
常用的策略：
1. 最终结果型缓存。这种缓存往往提升性能效果最为明显，但是命中率却低，也就是可重用性不高。
2. 中间结果型缓存。

缓存的策略又有如下常见的几种：
1. 永久式缓存：结果在任何情况下都不发生改变，无需清除或者更新
2. 有有效期的缓存：在特定时间点或者时间段后失效
3. 触发式失效缓存：当某一事件产生时，缓存失效，当然有有效期式缓存也可以理解成时间点和时间段到期为触发条件的
   触发式失效缓存

这两种缓存分别称之为：
1 被动式缓存：需要用到时才构建
2 主动式缓存：预先构建

---------------------------------------
2. Asynchronous
    Asynchronous 的意思是异步。什么是异步呢？就是不在第一时间告知调用者结果，告诉他我已经收到这个任务了，我会处理，
处理完毕后通知你结果，如果你不是等不到结果就无法进行下去的话，你完全可以先干别的事情。

---------------------------------------
3. Concurrent
    Concurrent 的意思是并行。现代化的 CPU 往往具有多个核心，而且有些 CPU 也具有超线程能力。如果我们可以将
单个过程拆分成小的任务，交给 CPU 的多个核心，或者是分布式计算系统的多个计算节点，就可以充分利用并行计算来提升性能。
前提是这些任务相互之间不要有相互依赖的关系。


最后再给一些小提示：
------------------------------------------------------------------------------
不要让 CPU 闲着（CPU
    正常情况下压力大的时候自然不会闲着，这里指的是CPU负载低谷时，可以让他主动的构建缓存，或者做一些准备工作等等。）
    提升 CPU 效率，即不要总让 CPU 做重复的劳动，用空间换时间的理念去减轻 CPU 的压力
    不要让无关紧要的附属的任务卡住主进程，让他们在后台慢慢做,可以提前做好准备工作，这个比较抽象，但是举例子就很明白，
连接池，主动缓存，以及我举得那个 Golang 的例子都是很好的
}

google(GOOGLE的建议){
    初始窗口调整到了10个MSS大小，这主要来自于GOOGLE的建议。原因是这样的，接收窗口虽然常以指数方式来快速增加窗口大小
（拥塞阀值以下是指数增长的，阀值以上进入拥塞避免阶段则为线性增长，而且，拥塞阀值自身在收到128以上数据报文时也有机会
快速增加），若是传输视频这样的大数据，那么随着窗口增加到（接近）最大读缓存后，就会“开足马力”传输数据，但若是通常都
是几十KB的网页，那么过小的初始窗口还没有增加到合适的窗口时，连接就结束了。这样相比较大的初始窗口，就使得用户需要更多
的时间（RTT）才能传输完数据，体验不好。
}

udp(风云推测){
我的思考结论就是：在 UDP 协议之上，实现一个带超时的请求回应机制，让业务层负责超时重发，有可能取得比 TCP 通讯
更好的效果。但其前提是：单个请求或回应的包不应该过大，最好不要超过一个 MTU ，在互联网上大约是 500 多字节。
}
tcp(other){
1、BSD TCP/IP协议栈
     BSD栈历史上是其他商业栈的起点，大多数专业TCP/IP栈（VxWorks内嵌的TCP/IP 栈）是BSD栈派生的。这是因为BSD栈在BSD许可协议下提供了这些专业栈的雏形，BSD许用证允许BSD栈以修改或未修改的形式结合这些专业栈的代码而无须向创建者付版税。同时，BSD也是许多TCP/IP协议中的创新（如广域网中饿拥塞控制和避免）的开始点。

2、uC/IP
    uC/IP是由Guy Lancaster编写的一套基于uC/OS且开放源码的TCP/IP协议栈，亦可移植到其它操作系统，是一套完全免费的、可供研究的TCP/IP协议栈，uC/IP大部分源码是从公开源码BSD发布站点和KA9Q（一个基于DOS单任务环境运行的TCP/IP协议栈）移植过来。uC/IP具有如下一些特点：带身份验证和报头压缩支持的PPP协议，优化的单一请求/回复交互过程，支持IP/TCP/UDP协议，可实现的网络功能较为强大，并可裁减。 UCIP协议栈被设计为一个带最小化用户接口及可应用串行链路网络模块。根据采用CPU、编译器和系统所需实现协议的多少，协议栈需要的代码容量空间在 30-60KB之间。http://ucip.sourceforge.net

3、LwIP
     LwIP是瑞士计算机科学院（Swedish Institute of Computer Science）的Adam Dunkels等开发的一套用于嵌入式系统的开放源代码TCP/IP协议栈。LwIP的含义是Light Weight(轻型)IP协议，相对于uip。LwIP可以移植到操作系统上，也可以在无操作系统的情况下独立运行。LwIP TCP/IP实现的重点是在保持TCP协议主要功能的基础上减少对RAM的占用，一般它只需要几十K的RAM和40K左右的ROM就可以运行，这使 LwIP协议栈适合在低端嵌入式系统中使用。LwIP的特性如下：支持多网络接口下的IP转发，支持ICMP协议，包括实验性扩展的的UDP（用户数据报协议），包括阻塞控制，RTT估算和快速恢复和快速转发的TCP（传输控制协议），提供专门的内部回调接口（Raw API）用于提高应用程序性能，并提供了可选择的Berkeley接口API。http://www.sics.se/~adam/lwip/或http://savannah.nongnu.org/projects/lwip/

4、uIP
    uIP是专门为8位和16位控制器设计的一个非常小的TCP/IP栈。完全用C编写，因此可移植到各种不同的结构和操作系统上，一个编译过的栈可以在几KB ROM或几百字节RAM中运行。uIP中还包括一个HTTP服务器作为服务内容。许可：BSD许用证http://www.sics.se/~adam/uip/

5、TinyTcp
    TinyTcp 栈是TCP/IP的一个非常小和简单的实现，它包括一个FTP客户。TinyTcp是为了烧入ROM设计的并且现在开始对大端结构似乎是有用的（初始目标是68000芯片）。TinyTcp也包括一个简单的以太网驱动器用于3COM多总线卡 http://ftp.ecs.soton.ac.uk/pub/elks/utils/tiny-tcp.txt
}

IP()
{
IP: 不可靠, 无连接的数据包传送服务.
**不可靠(unreliable)**: 没有确认的ACK机制 => 无法反馈成功/失败的数据包传输 => 
                        不能保证数据包成功到达 => 不可靠 (对比TCP, TCP是可靠的, 因为有 ACK/重传机制)
**无连接(connectionless)**: IP 不维护任何关于数据报的状态信息. 每个数据报是相互独立的.
                            (对比TCP: 建立连接时要握手, 消除连接时也要握手, 因此是有连接的)
**IP 首部**: 重点是 1. 生存时间 TTL(可以经过的最多路由器数, 一般为32/64. 字段减少到0时, 发送 ICMP 数据报通知源主机) 
                    2. 协议号(描述上层内容应该用哪个协议来解) 
                    3. IP source/dest 地址. 首部长 32bit, 传输顺序: 0-7, 8-15, 16-23, 24-31(网络字节序, big endian). 数据包最大值为 65535(2^16) Byte, 但一般都比较小(1024以下).
IP 选路
ip r show           # 路由规则
ip r show cache     # 路由缓存
}

TCP()
{
    连接(握手), 定时器(超时), 重排序, 流量控制(窗口大小). 传输的内容是8bit 字节流, 对内容不做任何解释. 
全双工(数据在两个方向上独立传输). 校验和覆盖整个报文: header + content.
断开的4次握手:
因为是全双工的, 两个方向都必须单独关闭(因为半关闭是允许的, 一个方向上收到 FIN 意味着这个方向关闭), 如图:
A ----FIN--------> B
    <--FIN-ACK----
    <--FIN----------
    ----FIN-ACK-->
半关闭最初是作为 remoteshell(rsh) 这样的程序通知 server 端自己的数据已经发送完毕出现的. 没有半关闭, 就需要其他的
一些技术通知 server 端传输完成.
}

tcp(TCP 交互数据流)
{
TCP 交互数据流： 成块数据(FTP, 电子邮件, 网络页面) 交互数据(telnet/rlogin)

    TCP同时处理这两种数据, 但是算法不同. 对于 rlogin, 每次交互按键都会产生一个数据分组(字符为单位而不是行为单位). 
每次按键会造成4个报文段:
1) 来自 client 的按键 2) server 的按键确认 3) server 回显 4) client 的回显确认. 通过时延确认技术, 2)3)可以一起发送

    经过时延的确认: 大多数实现时延200ms, 在此期间等待是否有同方向可以合并的 ACK. RFC 声明 TCP 需要实现经受时延的 ACK, 
但是时延小于 500ms

    Nagle 算法: rlogin 等程序带来的大量小分组在 WAN 上会增加拥塞出现的可能. Nagle 算法要求一个 TCP 连接中最多有一个
未被确认的小分组. 该分组的确认到达之前不能发送其他的小分组. -> 确认到达越快, 数据也就发送越快. 像 X Window Server 
这样需要无延迟发送小消息的(比如鼠标移动), 就要关闭 Nagle, 比如打开 TCP_NODELAY.
}

tcp(TCP 的超时与重传)
{
TCP 的超时与重传: 发送数据一半把网线拔了. 重传包的发送间隔为 1, 3, 6, 12, 24, 48, 64, 64,.. 显然的指数退避.
算法中的想法:
1. 平滑化: 过去的 srtt 有 alpha 的权值, 当前 rtt 是 1-alpha 的权值. alpha: 平滑因子: .8-.9
SRTT = ( ALPHA * SRTT ) + ((1-ALPHA) * RTT) => 平滑化在 Linux 中的应用挺多, 还包括 load 的计算.
2. 乘以一个参数并限制在上下界内: beta: delay variance factor 延迟方差因子: 1.3-2.0
RTO = min[UBOUND,max[LBOUND,(BETA*SRTT)］
}

tcp(拥塞避免)
{
对每个连接维护拥塞窗口 cwnd 和慢启动门限 ssthresh.
1. 初始化: cwnd = 1, ssthresh = 65535
2. output window size <= min(cwnd, receiver window size)
3. 慢启动
4. 发生拥塞后, ssthresh = max(cwnd/2, 2), cwnd = 1, enter slow start
5. When cwnd >= ssthresh, enter congestion avoidance.
}

tcp(快速重传 & 快速恢复)
{
    为什么一定要3个重复 ACK 才重传? => 我们不知道包是 1) 丢失了 2) 只是顺序被打乱, 在后面能收到.
    快速重传的算法针对3个重复 ACK 的情况, 基本是原算法直接跳过慢启动的过程, cwnd = ssthresh.
    前两个重复 ACK 到达时, cwnd 保持不变(对应于书中图21-10 中几段较为平坦的部分). 第三个重复 ACK 到达时, 
ssthresh被置为 cwnd 的一半, cwnd = ssthresh + 重复 ACK 数量*报文段大小.
    平滑化的 RTT, 均值偏差, ssthresh 在 TCP 连接关闭时以路由表项为 key 进行缓存. 下次使用路由表项时拿出来继续用.
}

tcp(TCP 的坚持定时器)
{
    如我们所知, TCP 不为其 ACK 包发送确认. 这可能导致死锁: 在 ACK 包丢失时, 发送方等待这个 ACK 包, 而接收方等待新的数据. 
为了阻止这种情况, 发送方使用一个坚持定时器(persistent timer) 周期性向接收方查询. 定时器到期后发送放发包, 检查窗口是否增大
(再通过返回的 ACK 就能看出当前 ACK 到多少了, 这样之前的 ACK 即使丢包也被弥补了). 这时发送方发出的报文称为窗口探查(window
 probe), 窗口探查也用的 TCP 的间隔时间指数退避, 60s 上限的做法.
 
    窗口探查说明了 TCP 的 server/client 端除了正经的数据传输外还是有藕断丝连的, 只要一方想绝交(window=0), 另一方就会跑个 
loop 去不断打探消息(当然, TCP 连接也是可以完全空白的, 双方建立了连接, 然后啥也不干, probe 都没有).
}

tcp(TCP 的保活定时器)
{
    保活定时器就是针对上述"建立连接后什么也不干"的一个 timeout, 这个 timeout 是系统级的, 作为应用设定 socket timeout 的
上界. 书中这个 timeout 是两小时, Linux kernel 中对应 TCP_KEEPALIVE_TIME 也是两小时, TCP_KEEPALIVE_PROBES 指定超时后最多
发送9次 probe, 如果都没有相应说明客户机已经关闭并终止连接.

probe 的结果可能有4种: 对端正常, 对端崩溃, 对端崩溃并重启, 无法连接到对端.
}

redis(tcp){
    1. 好的应用层协议是可伸缩的。一些应用层协议比如HTTP，会建立几条并行的链接的到服务端，这样做可以减少延迟，
增加吞吐量，但是在传输层和服务端看来，这些链接相互之间是没有关联关系的。而且可能会造成额外的一些问题。
    在传输层，比如TCP协议采用自适应算法根据网络的条件进行高效的数据传输。这个自适应的过程是在每个链接上进行
的。如果同时有多个链接到服务端，那也就是需要针对每个链接进行自适应的调节过程。这就在网络中引入了额外的不必要
的压力，而且TCP如果用了慢启动拥塞算法，那么，应用层序还是可以感受到这种额外的延迟。如果客户端的带宽不足，
这种问题反而会有可能变的更明显。
    在服务端，每个从客户端建立的链接有可能都要经过认证，因此，服务端的负载会随着远大于实际用户数的链接的
增加而增大。更严重的情况是，如果有一个用户发起了非常多的链接，服务端的性能可能会严重下降，甚至会导致无法
为其他用户提供服务。

    HTTP协议1.0版本，提供了持久链接机制(Keep-alive)，允许一个链接在处理完事务后可以不用关闭链接，以便为
将来的HTTP请求复用现存的链接。这种机制可以避开缓慢的链接建立阶段，而且还可以避免慢启动的拥塞适应阶段，
进行更快速的数据传输。但是管理持久链接时要特别小心，防止积累出大量的空闲链接，耗费本地以及远端的资源。
并行链接和持久链接配合使用可能是最高效的方式。
    类似HTTP的协议一般都是只允许客户端发送请求到服务端，而不允许服务端直接发送数据到客户端。当想要完成
服务端推送一些消息到客户端之类的业务需求时，只能让客户端不断的向服务端发送轮询请求。这样会导致浪费网络
资源，也会对服务端的资源造成浪费。所以后来引入了WeSocket,可以让HTTP链接转换为一般的链接，就可以避开
HTTP协议的要求了。
    另外就是类似HTTP的协议，一般都是一个请求发送过去，然后等待一个回应完成，然后再发下一个请求，这种
串行化处理会因为网络往返时延导致延迟较高。所以一般会用到Pipeline技术。也就是一次发送多个请求，要求服务端
按照相应的顺序发送回来。 这里面的重中之重就是服务端必须要确保发送的顺序是请求的顺序。还有就是如果客户端
发送了10个请求，但是服务端在处理完5个请求后发生了错误就关闭了链接，那么客户端就要确保能够重新发送剩余
的5个请求，这带来了一定的实现复杂度。
    但是类似HTTP的协议，在我看来还有另外一个好处。因为只允许客户端到服务端发送请求，那么会让C/S双方的
业务变得调理清晰。比如说，业务服务由客户端请求触发，专门有另外一个链接提供服务端推送数据到客户端。
这种职责单一性会带来更好的可维护性。而且这种职责单一性，可以很容易的用其他语言实现，也可以采用
同步阻塞IO或者非阻塞IO甚至异步IO机制实现。假设如果一个链接即处理业务请求，又能够让服务端推送数据，
那么更好的实现模型是event-driven，如果用同步阻塞IO实现，就会变得异常复杂。在我最近的接触中，发现
REDIS的协议就是此种设计。REDIS的协议里大部分都是客户端发起请求，服务端处理后返回结果； 但是有一个特殊的请求，
就是SUBSCRIBE，客户端发起这个命令后，如果再通过这个链接发送数据到服务端，服务端会直接返回错误。
处于SUBSCRIBE状态的链接只能等着服务端主动推送来的数据。 
    可伸缩性的另外一个方面就是服务端和客户端的部署关系。功能实现在服务端总是比实现在客户端能够带来更多的
可伸缩性，毕竟大多数情况下，服务端升级总是要比客户端容易一些。

    2. 好的应用层协议是高效的。我们大多数都会非常关心传输的效率，总是认为传输速度越快越好。一般的做法
是批量请求，一个请求中包含了很多要一起处理的事情；或者重叠请求，比如HTTP PIPELINE机制和IMAP中针对请求
打标机的方式，让客户端无需等待回应就可以继续向服务端发送请求，然后在接收时可以通过客户端的状态机处理
回应数据，这样就能够减少等待时间。有些时候，性能可能会和扩展性产生冲突，这个时候就需要自己根据实际场景
和需求做权衡。

    3. 好的应用层协议是简单的。经验法则是如果一个协议设计的很差，那么在做一些简单的事情时反而变成了挑战。
正确的方式是让简单的事情简单的完成，复杂的事情通过复杂的方式完成。另外一条经验法则是，如果应用层协议有
两种方式完成同样的事情，那么可能在基础协议设计架构上存在问题。简单并不意味着想法简单，而是说，简单是一种
精心设计的，可以解决包括了问题域中的任何事情，甚至是边界的更复杂的问题。一致性是会让设计变得优雅和简单。

    4. 好的应用层协议是可扩展的。我们程序员经常会遇到需求的变更，或者一些策略变动较多的问题。这也就意味着，
协议本身是逐步演进的。所以一个可扩展的协议对我们来说非常的重要。可扩展的协议可以方便的向前或者向后兼容，
比如protobuff，json，http等协议。

    5. 好的应用层协议是人类可读的。可读性要根据自己实际场景和需要进行权衡。但是在我个人看来，可读的协议
容易帮助排查问题。想象一下，遇到了一个网络问题，需要抓包分析，满眼的二进制流是什么感受？再想象下，如果
是HTTP协议，你还有这种困难么？

    6. 好的应用层协议是健壮的。Postel的健壮性法则be conservative in what you send, be liberal in what 
you accept.(发送时保守，接手时开放)”讲究的更多的是吞掉对方的错误，但是如果对接收到的数据进行检查并返回
了错误，那么对对方可能会有更多的好处。假设跨语言实现的时候或者多版本客户端的时候，如果没有一个一致的
错误检查，会让人很蛋疼的吧。
}

redis(proto){
Redis 协议在以下三个目标之间进行折中：
1. 易于实现
2. 可以高效地被计算机分析（parse）
3. 可以很容易地被人类读懂


网络层
1. 客户端和服务器通过 TCP 连接来进行数据交互， 服务器默认的端口号为 6379 。
2. 客户端和服务器发送的命令或数据一律以 \r\n （CRLF）结尾。


请求
1. Redis 服务器接受命令以及命令的参数。
2. 服务器会在接到命令之后，对命令进行处理，并将命令的回复传送回客户端。

新版统一请求协议
1. 在这个协议中， 所有发送至 Redis 服务器的参数都是二进制安全（binary safe）的。

回复
Redis 命令会返回多种不同类型的回复。
通过检查服务器发回数据的第一个字节， 可以确定这个回复是什么类型：

    状态回复（status reply）的第一个字节是 "+"
    错误回复（error reply）的第一个字节是 "-"
    整数回复（integer reply）的第一个字节是 ":"
    批量回复（bulk reply）的第一个字节是 "$"
    多条批量回复（multi bulk reply）的第一个字节是 "*"
    
1. 状态回复
一个状态回复（或者单行回复，single line reply）是一段以 "+" 开始、 "\r\n" 结尾的单行字符串。
以下是一个状态回复的例子：
+OK
客户端库应该返回 "+" 号之后的所有内容。 比如在在上面的这个例子中， 客户端就应该返回字符串 "OK" 。
状态回复通常由那些不需要返回数据的命令返回，这种回复不是二进制安全的，它也不能包含新行。
状态回复的额外开销非常少，只需要三个字节（开头的 "+" 和结尾的 CRLF）。

2. 错误回复
    错误回复和状态回复非常相似， 它们之间的唯一区别是， 错误回复的第一个字节是 "-" ， 
而状态回复的第一个字节是 "+" 。
    错误回复只在某些地方出现问题时发送： 比如说， 当用户对不正确的数据类型执行命令， 
或者执行一个不存在的命令， 等等。
    一个客户端库应该在收到错误回复时产生一个异常。
    以下是两个错误回复的例子：
-ERR unknown command 'foobar'
-WRONGTYPE Operation against a key holding the wrong kind of value
    在 "-" 之后，直到遇到第一个空格或新行为止，这中间的内容表示所返回错误的类型。
    ERR 是一个通用错误，而 WRONGTYPE 则是一个更特定的错误。 一个客户端实现可以为不同类型的错误产生
不同类型的异常， 或者提供一种通用的方式， 让调用者可以通过提供字符串形式的错误名来捕捉（trap）不同的错误。
    不过这些特性用得并不多， 所以并不是特别重要， 一个受限的（limited）客户端可以通过简单地返回一个逻辑假
（false）来表示一个通用的错误条件。

3. 整数回复
    整数回复就是一个以 ":" 开头， CRLF 结尾的字符串表示的整数。
    比如说， ":0\r\n" 和 ":1000\r\n" 都是整数回复。
    返回整数回复的其中两个命令是 INCR 和 LASTSAVE 。 被返回的整数没有什么特殊的含义， INCR 返回键的
一个自增后的整数值， 而 LASTSAVE 则返回一个 UNIX 时间戳， 返回值的唯一限制是这些数必须能够用 64 位有
符号整数表示。
    整数回复也被广泛地用于表示逻辑真和逻辑假： 比如 EXISTS 和 SISMEMBER 都用返回值 1 表示真， 0 表示假。
    其他一些命令， 比如 SADD 、 SREM 和 SETNX ， 只在操作真正被执行了的时候， 才返回 1 ， 否则返回 0 。
    以下命令都返回整数回复： SETNX 、 DEL 、 EXISTS 、 INCR 、 INCRBY 、 DECR 、 DECRBY 、 DBSIZE 、 
LASTSAVE 、 RENAMENX 、 MOVE 、 LLEN 、 SADD 、 SREM 、 SISMEMBER 、 SCARD 。

4. 批量回复
服务器使用批量回复来返回二进制安全的字符串，字符串的最大长度为 512 MB 。
客户端：GET mykey
服务器：foobar

服务器发送的内容中：
    第一字节为 "$" 符号
    接下来跟着的是表示实际回复长度的数字值
    之后跟着一个 CRLF
    再后面跟着的是实际回复数据
    最末尾是另一个 CRLF

对于前面的 GET 命令，服务器实际发送的内容为：
"$6\r\nfoobar\r\n"
如果被请求的值不存在， 那么批量回复会将特殊值 -1 用作回复的长度值， 就像这样：
客户端：GET non-existing-key
服务器：$-1
这种回复称为空批量回复（NULL Bulk Reply）。
    当请求对象不存在时，客户端应该返回空对象，而不是空字符串： 比如 Ruby 库应该返回 nil ， 而 C 库应该返回
 NULL （或者在回复对象中设置一个特殊标志）， 诸如此类。


5. 多条批量回复¶
像 LRANGE 这样的命令需要返回多个值， 这一目标可以通过多条批量回复来完成。
多条批量回复是由多个回复组成的数组， 数组中的每个元素都可以是任意类型的回复， 包括多条批量回复本身。
    多条批量回复的第一个字节为 "*" ， 后跟一个字符串表示的整数值， 这个值记录了多条批量回复所包含的回复数量， 
再后面是一个 CRLF 。

客户端： LRANGE mylist 0 3
服务器： *4
服务器： $3
服务器： foo
服务器： $3
服务器： bar
服务器： $5
服务器： Hello
服务器： $5
服务器： World

在上面的示例中，服务器发送的所有字符串都由 CRLF 结尾。
正如你所见到的那样， 多条批量回复所使用的格式， 和客户端发送命令时使用的统一请求协议的格式一模一样。 它们之间的唯一区别是：
    统一请求协议只发送批量回复。
    而服务器应答命令时所发送的多条批量回复，则可以包含任意类型的回复。
以下例子展示了一个多条批量回复， 回复中包含四个整数值， 以及一个二进制安全字符串：
*5\r\n
:1\r\n
:2\r\n
:3\r\n
:4\r\n
$6\r\n
foobar\r\n
在回复的第一行， 服务器发送 *5\r\n ， 表示这个多条批量回复包含 5 条回复， 再后面跟着的则是 5 条回复的正文。
多条批量回复也可以是空白的（empty）， 就像这样：
客户端： LRANGE nokey 0 1
服务器： *0\r\n
无内容的多条批量回复（null multi bulk reply）也是存在的， 比如当 BLPOP 命令的阻塞时间超过最大时限时， 它就返回一个无内容的多条批量回复， 这个回复的计数值为 -1 ：
客户端： BLPOP key 1
服务器： *-1\r\n
客户端库应该区别对待空白多条回复和无内容多条回复： 当 Redis 返回一个无内容多条回复时， 客户端库应该返回一个 null 对象， 而不是一个空数组。
多条批量回复中的空元素

多条批量回复中的元素可以将自身的长度设置为 -1 ， 从而表示该元素不存在， 并且也不是一个空白字符串（empty string）。

当 SORT 命令使用 GET pattern 选项对一个不存在的键进行操作时， 就会发生多条批量回复中带有空白元素的情况。

以下例子展示了一个包含空元素的多重批量回复：

服务器： *3
服务器： $3
服务器： foo
服务器： $-1
服务器： $3
服务器： bar

其中， 回复中的第二个元素为空。

对于这个回复， 客户端库应该返回类似于这样的回复：

["foo", nil, "bar"]

6. 多命令和流水线
客户端可以通过流水线， 在一次写入操作中发送多个命令：
    在发送新命令之前， 无须阅读前一个命令的回复。
    多个命令的回复会在最后一并返回。

7. 内联命令
当你需要和 Redis 服务器进行沟通， 但又找不到 redis-cli ， 而手上只有 telnet 的时候， 你可以通过 Redis 特别为这种情形而设的内联命令格式来发送命令。
以下是一个客户端和服务器使用内联命令来进行交互的例子：
客户端： PING
服务器： +PONG
以下另一个返回整数值的内联命令的例子：
客户端： EXISTS somekey
服务器： :0
因为没有了统一请求协议中的 "*" 项来声明参数的数量， 所以在 telnet 会话输入命令的时候， 必须使用空格来分割各个参数， 服务器在接收到数据之后， 会按空格对用户的输入进行分析（parse）， 并获取其中的命令参数。

}
Protobuf(tcp){

}
mcpack(){

}
dubbo(){

}
URL(){
URI：统一资源标示符。

URL：统一资源定位符，也就是说根据URL能够定位到网络上的某个资源，它是指向互联网“资源”的指针。

每个URL都是URI，但不一定每个URI都是URL。这是因为URI还包括一个子类，即统一资源名称（URN），它命名资源但不指定如何定位资源。
}